{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\prans\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "import re\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"Dataset/CSV/edos_labelled_aggregated.csv\")\n",
    "df_2 = pd.read_csv(\"Dataset/CSV/edos_labelled_individual_annotations.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2_sexisms = df_2[df_2['label_sexist'] == 'sexist']\n",
    "df_2_nonsexisms = df_2[df_2['label_sexist'] == 'not sexist']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2_nonsexisms = df_2_nonsexisms.sample(n=7000, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2_sexisms = df_2_sexisms[['text', 'label_sexist' , 'split']]\n",
    "df_2_nonsexisms = df_2_nonsexisms[['text', 'label_sexist' , 'split']]\n",
    "df = df[['text', 'label_sexist' , 'split']]\n",
    "df_final = pd.concat([df , df_2_sexisms, df_2_nonsexisms])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_final.sample(frac=1, random_state=42).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "text            0\n",
       "label_sexist    0\n",
       "split           0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"label_sexist\"] = df[\"label_sexist\"].map({\"sexist\": 1, \"not sexist\": 0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label_sexist</th>\n",
       "      <th>split</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Women of an earlier decade were taught about p...</td>\n",
       "      <td>1</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Must have been a white woman so she had to sho...</td>\n",
       "      <td>0</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>This is her political suicide tweet. Please sh...</td>\n",
       "      <td>0</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Go suck your daddy's cock.... if you can figur...</td>\n",
       "      <td>1</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>As a fairly productive member of society who w...</td>\n",
       "      <td>0</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  label_sexist  split\n",
       "0  Women of an earlier decade were taught about p...             1  train\n",
       "1  Must have been a white woman so she had to sho...             0   test\n",
       "2  This is her political suicide tweet. Please sh...             0  train\n",
       "3  Go suck your daddy's cock.... if you can figur...             1  train\n",
       "4  As a fairly productive member of society who w...             0  train"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label_sexist\n",
       "0    22146\n",
       "1    20184\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"label_sexist\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_url(text):\n",
    "    url = re.compile(r'https?://\\S+|www\\.\\S+')\n",
    "    return url.sub(r'', text)\n",
    "\n",
    "\n",
    "def remove_html(text):\n",
    "    html = re.compile(r'<.*?>')\n",
    "    return html.sub(r'', text)\n",
    "\n",
    "\n",
    "def remove_emoji(text):\n",
    "    emoji_pattern = re.compile(\"[\"\n",
    "                               u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "                               u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "                               u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "                               u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
    "                               u\"\\U00002702-\\U000027B0\"\n",
    "                               u\"\\U000024C2-\\U0001F251\"\n",
    "                               \"]+\", flags=re.UNICODE)\n",
    "    return emoji_pattern.sub(r'', text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def special_characters(text):\n",
    "\n",
    "    text = re.sub(r\"SuruÃŒÂ¤\", \"Suruc\", text)\n",
    "    text = re.sub(r\"JapÃŒ_n\", \"Japan\", text)\n",
    "    text = re.sub(r\"\\x89Ã›ÃWhen\", \"When\", text)\n",
    "    text = re.sub(r\"Ã¥Â£3million\", \"3 million\", text)\n",
    "    text = re.sub(r\"fromÃ¥ÃŠwounds\", \"from wounds\", text)\n",
    "    text = re.sub(r\"mÃŒÂ¼sica\", \"music\", text)\n",
    "    text = re.sub(r\"donÃ¥Â«t\", \"do not\", text)\n",
    "    text = re.sub(r\"didn`t\", \"did not\", text)\n",
    "    text = re.sub(r\"i\\x89Ã›Âªm\", \"I am\", text)\n",
    "    text = re.sub(r\"I\\x89Ã›Âªm\", \"I am\", text)\n",
    "    text = re.sub(r\"it\\x89Ã›Âªs\", \"it is\", text)\n",
    "    text = re.sub(r\"It\\x89Ã›Âªs\", \"It is\", text)\n",
    "    text = re.sub(r\"i\\x89Ã›Âªd\", \"I would\", text)\n",
    "    text = re.sub(r\"I\\x89Ã›Âªd\", \"I would\", text)\n",
    "    text = re.sub(r\"i\\x89Ã›Âªve\", \"I have\", text)\n",
    "    text = re.sub(r\"I\\x89Ã›Âªve\", \"I have\", text)\n",
    "    text = re.sub(r\"let\\x89Ã›Âªs\", \"let us\", text)\n",
    "    text = re.sub(r\"don\\x89Ã›Âªt\", \"do not\", text)\n",
    "    text = re.sub(r\"Don\\x89Ã›Âªt\", \"Do not\", text)\n",
    "    text = re.sub(r\"can\\x89Ã›Âªt\", \"cannot\", text)\n",
    "    text = re.sub(r\"Can\\x89Ã›Âªt\", \"Cannot\", text)\n",
    "    text = re.sub(r\"that\\x89Ã›Âªs\", \"that is\", text)\n",
    "    text = re.sub(r\"That\\x89Ã›Âªs\", \"That is\", text)\n",
    "    text = re.sub(r\"here\\x89Ã›Âªs\", \"here is\", text)\n",
    "    text = re.sub(r\"Here\\x89Ã›Âªs\", \"Here is\", text)\n",
    "    text = re.sub(r\"you\\x89Ã›Âªre\", \"you are\", text)\n",
    "    text = re.sub(r\"You\\x89Ã›Âªre\", \"You are\", text)\n",
    "    text = re.sub(r\"you\\x89Ã›Âªve\", \"you have\", text)\n",
    "    text = re.sub(r\"You\\x89Ã›Âªve\", \"You have\", text)\n",
    "    text = re.sub(r\"you\\x89Ã›Âªll\", \"you will\", text)\n",
    "    text = re.sub(r\"You\\x89Ã›Âªll\", \"You will\", text)\n",
    "    text = re.sub(r\"China\\x89Ã›Âªs\", \"China's\", text)\n",
    "    text = re.sub(r\"doesn\\x89Ã›Âªt\", \"does not\", text)\n",
    "    text = re.sub(r\"wouldn\\x89Ã›Âªt\", \"would not\", text)\n",
    "    text = re.sub(r\"\\x89Ã›_\", \"\", text)\n",
    "    text = re.sub(r\"\\x89Ã›Â¢\", \"\", text)\n",
    "    text = re.sub(r\"\\x89Ã›Ã’\", \"\", text)\n",
    "    text = re.sub(r\"\\x89Ã›Ã“\", \"\", text)\n",
    "    text = re.sub(r\"\\x89Ã›Ã\", \"\", text)\n",
    "    text = re.sub(r\"\\x89Ã›Ã·\", \"\", text)\n",
    "    text = re.sub(r\"\\x89Ã›Âª\", \"\", text)\n",
    "    text = re.sub(r\"\\x89Ã›Â¢Ã¥ÃŠ\", \"\", text)\n",
    "    text = re.sub(r\"\\x89Ã›\\x9d\", \"\", text)\n",
    "    text = re.sub(r\"Ã¥_\", \"\", text)\n",
    "    text = re.sub(r\"Ã¥Â¨\", \"\", text)\n",
    "    text = re.sub(r\"Ã¥Ã€\", \"\", text)\n",
    "    text = re.sub(r\"Ã¥Ã‡\", \"\", text)\n",
    "    text = re.sub(r\"Ã¥ÃŠ\", \"\", text)\n",
    "    text = re.sub(r\"Ã¥Ãˆ\", \"\", text)\n",
    "    text = re.sub(r\"ÃŒÂ©\", \"\", text)\n",
    "\n",
    "    text = re.sub(r\"&lt;\", \"<\", text)\n",
    "    text = re.sub(r\"&gt;\", \">\", text)\n",
    "    text = re.sub(r\"&amp;\", \"&\", text)\n",
    "    return text\n",
    "\n",
    "\n",
    "def remove_nonASCII(text):\n",
    "    text = ''.join([x for x in text if x in string.printable])\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def specific_corrections(text):\n",
    "\n",
    "    text = re.sub(r\"b/c\", \"because\", text)\n",
    "    text = re.sub(r\"w/e\", \"whatever\", text)\n",
    "    text = re.sub(r\"w/out\", \"without\", text)\n",
    "    text = re.sub(r\"w/o\", \"without\", text)\n",
    "    text = re.sub(r\"w/\", \"with \", text)\n",
    "    text = re.sub(r\"<3\", \"love\", text)\n",
    "    text = re.sub(r\"c/o\", \"care of\", text)\n",
    "    text = re.sub(r\"p/u\", \"pick up\", text)\n",
    "    text = re.sub(r\"\\n\", \" \", text)\n",
    "\n",
    "    text = re.sub(r\"Trfc\", \"Traffic\", text)\n",
    "    text = re.sub(r\"recentlu\", \"recently\", text)\n",
    "    text = re.sub(r\"Ph0tos\", \"Photos\", text)\n",
    "    text = re.sub(r\"exp0sed\", \"exposed\", text)\n",
    "    text = re.sub(r\"amageddon\", \"armageddon\", text)\n",
    "    text = re.sub(r\"TRAUMATISED\", \"traumatized\", text)\n",
    "    text = re.sub(r\"Newss\", \"News\", text)\n",
    "    text = re.sub(r\"remedyyyy\", \"remedy\", text)\n",
    "    text = re.sub(r\"Bstrd\", \"bastard\", text)\n",
    "    text = re.sub(r\"bldy\", \"bloody\", text)\n",
    "    text = re.sub(r\"epicenterr\", \"epicenter\", text)\n",
    "    text = re.sub(r\"approachng\", \"approaching\", text)\n",
    "    text = re.sub(r\"evng\", \"evening\", text)\n",
    "    text = re.sub(r\"Sumthng\", \"something\", text)\n",
    "    text = re.sub(r\"kostumes\", \"costumes\", text)\n",
    "    text = re.sub(r\"glowng\", \"glowing\", text)\n",
    "    text = re.sub(r\"kindlng\", \"kindling\", text)\n",
    "    text = re.sub(r\"riggd\", \"rigged\", text)\n",
    "    text = re.sub(r\"HLPS\", \"helps\", text)\n",
    "    text = re.sub(r\"SNCTIONS\", \"sanctions\", text)\n",
    "    text = re.sub(r\"Politifiact\", \"PolitiFact\", text)\n",
    "    text = re.sub(r\"Kowing\", \"Knowing\", text)\n",
    "    text = re.sub(r\"wrld\", \"world\", text)\n",
    "    text = re.sub(r\"shld\", \"should\", text)\n",
    "    text = re.sub(r\"thruuu\", \"through\", text)\n",
    "    text = re.sub(r\"probaly\", \"probably\", text)\n",
    "    text = re.sub(r\"whatevs\", \"whatever\", text)\n",
    "    text = re.sub(r\"colomr\", \"colour\", text)\n",
    "    text = re.sub(r\"pileq\", \"pile\", text)\n",
    "    text = re.sub(r\"firefightr\", \"firefighter\", text)\n",
    "    text = re.sub(r\"LAIGHIGN\", \"laughing\", text)\n",
    "    text = re.sub(r\"EXCLUSIV\", \"Exclusive\", text)\n",
    "    text = re.sub(r\"belo-ooow\", \"below\", text)\n",
    "    text = re.sub(r\"who-ooo-ole\", \"whole\", text)\n",
    "    text = re.sub(r\"brother-n-law\", \"father-in-law\", text)\n",
    "    text = re.sub(r\"referencereference\", \"reference\", text)\n",
    "\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def expand_contractions(text):\n",
    "\n",
    "    text = re.sub(r\"I'm\", \"I am\", text)\n",
    "    text = re.sub(r\"I'M\", \"I am\", text)\n",
    "    text = re.sub(r\"i'm\", \"I am\", text)\n",
    "    text = re.sub(r\"i'M\", \"I am\", text)\n",
    "    text = re.sub(r\"i'd\", \"I would\", text)\n",
    "    text = re.sub(r\"I'd\", \"I would\", text)\n",
    "    text = re.sub(r\"i'll\", \"I will\", text)\n",
    "    text = re.sub(r\"I'll\", \"I will\", text)\n",
    "    text = re.sub(r\"i've\", \"I have\", text)\n",
    "    text = re.sub(r\"I've\", \"I have\", text)\n",
    "    text = re.sub(r\"you're\", \"you are\", text)\n",
    "    text = re.sub(r\"You're\", \"You are\", text)\n",
    "    text = re.sub(r\"you'd\", \"you would\", text)\n",
    "    text = re.sub(r\"You'd\", \"You would\", text)\n",
    "    text = re.sub(r\"you've\", \"you have\", text)\n",
    "    text = re.sub(r\"You've\", \"You have\", text)\n",
    "    text = re.sub(r\"you'll\", \"you will\", text)\n",
    "    text = re.sub(r\"You'll\", \"You will\", text)\n",
    "    text = re.sub(r\"y'know\", \"you know\", text)\n",
    "    text = re.sub(r\"Y'know\", \"You know\", text)\n",
    "    text = re.sub(r\"y'all\", \"you all\", text)\n",
    "    text = re.sub(r\"Y'all\", \"You all\", text)\n",
    "    text = re.sub(r\"we're\", \"we are\", text)\n",
    "    text = re.sub(r\"We're\", \"We are\", text)\n",
    "    text = re.sub(r\"we've\", \"we have\", text)\n",
    "    text = re.sub(r\"We've\", \"We have\", text)\n",
    "    text = re.sub(r\"we'd\", \"we would\", text)\n",
    "    text = re.sub(r\"We'd\", \"We would\", text)\n",
    "    text = re.sub(r\"WE'VE\", \"We have\", text)\n",
    "    text = re.sub(r\"we'll\", \"we will\", text)\n",
    "    text = re.sub(r\"We'll\", \"We will\", text)\n",
    "    text = re.sub(r\"they're\", \"they are\", text)\n",
    "    text = re.sub(r\"They're\", \"They are\", text)\n",
    "    text = re.sub(r\"they'd\", \"they would\", text)\n",
    "    text = re.sub(r\"They'd\", \"They would\", text)\n",
    "    text = re.sub(r\"they've\", \"they have\", text)\n",
    "    text = re.sub(r\"They've\", \"They have\", text)\n",
    "    text = re.sub(r\"they'll\", \"they will\", text)\n",
    "    text = re.sub(r\"They'll\", \"They will\", text)\n",
    "    text = re.sub(r\"he's\", \"he is\", text)\n",
    "    text = re.sub(r\"He's\", \"He is\", text)\n",
    "    text = re.sub(r\"he'll\", \"he will\", text)\n",
    "    text = re.sub(r\"He'll\", \"He will\", text)\n",
    "    text = re.sub(r\"she's\", \"she is\", text)\n",
    "    text = re.sub(r\"She's\", \"She is\", text)\n",
    "    text = re.sub(r\"she'll\", \"she will\", text)\n",
    "    text = re.sub(r\"She'll\", \"She will\", text)\n",
    "    text = re.sub(r\"it's\", \"it is\", text)\n",
    "    text = re.sub(r\"It's\", \"It is\", text)\n",
    "    text = re.sub(r\"it'll\", \"it will\", text)\n",
    "    text = re.sub(r\"It'll\", \"It will\", text)\n",
    "    text = re.sub(r\"isn't\", \"is not\", text)\n",
    "    text = re.sub(r\"Isn't\", \"Is not\", text)\n",
    "    text = re.sub(r\"who's\", \"who is\", text)\n",
    "    text = re.sub(r\"Who's\", \"Who is\", text)\n",
    "    text = re.sub(r\"what's\", \"what is\", text)\n",
    "    text = re.sub(r\"What's\", \"What is\", text)\n",
    "    text = re.sub(r\"that's\", \"that is\", text)\n",
    "    text = re.sub(r\"That's\", \"That is\", text)\n",
    "    text = re.sub(r\"here's\", \"here is\", text)\n",
    "    text = re.sub(r\"Here's\", \"Here is\", text)\n",
    "    text = re.sub(r\"there's\", \"there is\", text)\n",
    "    text = re.sub(r\"There's\", \"There is\", text)\n",
    "    text = re.sub(r\"where's\", \"where is\", text)\n",
    "    text = re.sub(r\"Where's\", \"Where is\", text)\n",
    "    text = re.sub(r\"wHeRE's\", \"where is\", text)\n",
    "    text = re.sub(r\"how's\", \"how is\", text)\n",
    "    text = re.sub(r\"How's\", \"How is\", text)\n",
    "    text = re.sub(r\"how're\", \"how are\", text)\n",
    "    text = re.sub(r\"How're\", \"How are\", text)\n",
    "    text = re.sub(r\"let's\", \"let us\", text)\n",
    "    text = re.sub(r\"Let's\", \"Let us\", text)\n",
    "    text = re.sub(r\"won't\", \"will not\", text)\n",
    "    text = re.sub(r\"wasn't\", \"was not\", text)\n",
    "    text = re.sub(r\"aren't\", \"are not\", text)\n",
    "    text = re.sub(r\"couldn't\", \"could not\", text)\n",
    "    text = re.sub(r\"shouldn't\", \"should not\", text)\n",
    "    text = re.sub(r\"haven't\", \"have not\", text)\n",
    "    text = re.sub(r\"Haven't\", \"Have not\", text)\n",
    "    text = re.sub(r\"hasn't\", \"has not\", text)\n",
    "    text = re.sub(r\"wouldn't\", \"would not\", text)\n",
    "    text = re.sub(r\"weren't\", \"were not\", text)\n",
    "    text = re.sub(r\"Weren't\", \"Were not\", text)\n",
    "    text = re.sub(r\"ain't\", \"am not\", text)\n",
    "    text = re.sub(r\"Ain't\", \"am not\", text)\n",
    "    text = re.sub(r\"don't\", \"do not\", text)\n",
    "    text = re.sub(r\"Don't\", \"do not\", text)\n",
    "    text = re.sub(r\"DON'T\", \"Do not\", text)\n",
    "    text = re.sub(r\"didn't\", \"did not\", text)\n",
    "    text = re.sub(r\"Didn't\", \"Did not\", text)\n",
    "    text = re.sub(r\"DIDN'T\", \"Did not\", text)\n",
    "    text = re.sub(r\"doesn't\", \"does not\", text)\n",
    "    text = re.sub(r\"can't\", \"cannot\", text)\n",
    "    text = re.sub(r\"Can't\", \"Cannot\", text)\n",
    "    text = re.sub(r\"Could've\", \"Could have\", text)\n",
    "    text = re.sub(r\"should've\", \"should have\", text)\n",
    "    text = re.sub(r\"would've\", \"would have\", text)\n",
    "\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_non_alnum(text):\n",
    "    punctuation = re.compile('[^A-Za-z0-9]+')\n",
    "    return punctuation.sub(r' ', text)\n",
    "\n",
    "\n",
    "def remove_punct(text):\n",
    "    table = str.maketrans('', '', string.punctuation)\n",
    "    return text.translate(table)\n",
    "\n",
    "\n",
    "def remove_extra_spaces(text):\n",
    "    text = re.sub('\\s+', ' ', text).strip()\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample sentence :\n",
      "I say let her continue to be an idiot and move on.\n",
      "\n",
      "Preprocessed sentence :\n",
      "i say let her continue to be an idiot and move on\n"
     ]
    }
   ],
   "source": [
    "# first remove all the characters except the alphabets\n",
    "import re\n",
    "import random\n",
    "\n",
    "\n",
    "def prep_text(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'http\\S+', '', text)  # Removing the links\n",
    "    text = re.sub(r'#\\w+', '', text)  # removing the hashtags\n",
    "    text = re.sub(r'@\\w+', '', text)  # removing the mentions @\n",
    "    text = re.sub(r'[^a-z ]', '', text)  # removing characters other than a-z\n",
    "    text = remove_emoji(text)  # removing the emojis\n",
    "    text = remove_html(text)  # removing the html tags\n",
    "    text = remove_punct(text)  # removing the punctuations\n",
    "    text = specific_corrections(text)  # correcting some specific words\n",
    "    text = expand_contractions(text)  # expanding the contractions\n",
    "    text = remove_nonASCII(text)  # removing the non-ascii characters\n",
    "    text = special_characters(text)  # removing the special characters\n",
    "    text = remove_non_alnum(text)  # removing the non-alphanumeric characters\n",
    "    text = remove_extra_spaces(text)  # removing the extra spaces\n",
    "    text = text.strip()  # removing the whitespaces\n",
    "\n",
    "    return text\n",
    "\n",
    "\n",
    "sample = df[\"text\"].sample(random_state=42).values[0]\n",
    "print(f\"Sample sentence :\\n{sample}\\n\")\n",
    "print(f\"Preprocessed sentence :\")\n",
    "print(prep_text(sample))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"text\"] = df[\"text\"].apply(prep_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the data into training and validation sets\n",
    "df_train = df[df[\"split\"] == \"train\"]\n",
    "df_val = df[df[\"split\"] == \"dev\"]\n",
    "df_test = df[df[\"split\"] == \"test\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = df_train[\"text\"]\n",
    "y_train = df_train[\"label_sexist\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LLM Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simple Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\prans\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import tensorflow_hub as hub\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\prans\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow_hub\\resolver.py:120: The name tf.gfile.MakeDirs is deprecated. Please use tf.io.gfile.makedirs instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\prans\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow_hub\\resolver.py:120: The name tf.gfile.MakeDirs is deprecated. Please use tf.io.gfile.makedirs instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\prans\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow_hub\\module_v2.py:126: The name tf.saved_model.load_v2 is deprecated. Please use tf.compat.v2.saved_model.load instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\prans\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow_hub\\module_v2.py:126: The name tf.saved_model.load_v2 is deprecated. Please use tf.compat.v2.saved_model.load instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 512)\n"
     ]
    }
   ],
   "source": [
    "# âœ… Load Google's Universal Sentence Encoder\n",
    "use_model = hub.load(\"https://tfhub.dev/google/universal-sentence-encoder/4\")\n",
    "\n",
    "\n",
    "def get_embeddings(texts):\n",
    "    return use_model(texts).numpy()\n",
    "\n",
    "\n",
    "# Example:\n",
    "sample_texts = [\"This is a test sentence.\",\n",
    "                \"Sexist comments should be flagged.\"]\n",
    "embeddings = get_embeddings(sample_texts)\n",
    "\n",
    "print(embeddings.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: saved_use_model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: saved_use_model\\assets\n"
     ]
    }
   ],
   "source": [
    "local_model_path = \"saved_use_model\"\n",
    "\n",
    "# Save the model\n",
    "tf.saved_model.save(use_model, local_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (29574, 512)\n",
      "y_train shape: (29574,)\n"
     ]
    }
   ],
   "source": [
    "# Convert text data to embeddings\n",
    "X_train_embeddings = get_embeddings(df_train[\"text\"].tolist())\n",
    "\n",
    "# Convert labels to NumPy array\n",
    "y_train = df_train[\"label_sexist\"].values\n",
    "\n",
    "# Print shape\n",
    "print(\"X_train shape:\", X_train_embeddings.shape)  # (num_samples, 512)\n",
    "print(\"y_train shape:\", y_train.shape)  # (num_samples,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_10\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_10\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
       "â”ƒ<span style=\"font-weight: bold\"> Layer (type)                    </span>â”ƒ<span style=\"font-weight: bold\"> Output Shape           </span>â”ƒ<span style=\"font-weight: bold\">       Param # </span>â”ƒ\n",
       "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
       "â”‚ dense_43 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            â”‚       <span style=\"color: #00af00; text-decoration-color: #00af00\">131,328</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ batch_normalization_20          â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            â”‚         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            â”‚                        â”‚               â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dropout_33 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense_44 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            â”‚        <span style=\"color: #00af00; text-decoration-color: #00af00\">32,896</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ batch_normalization_21          â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            â”‚           <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            â”‚                        â”‚               â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dropout_34 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense_45 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             â”‚         <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dropout_35 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense_46 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              â”‚            <span style=\"color: #00af00; text-decoration-color: #00af00\">65</span> â”‚\n",
       "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
       "</pre>\n"
      ],
      "text/plain": [
       "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
       "â”ƒ\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0mâ”ƒ\n",
       "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
       "â”‚ dense_43 (\u001b[38;5;33mDense\u001b[0m)                â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            â”‚       \u001b[38;5;34m131,328\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ batch_normalization_20          â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            â”‚         \u001b[38;5;34m1,024\u001b[0m â”‚\n",
       "â”‚ (\u001b[38;5;33mBatchNormalization\u001b[0m)            â”‚                        â”‚               â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dropout_33 (\u001b[38;5;33mDropout\u001b[0m)            â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            â”‚             \u001b[38;5;34m0\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense_44 (\u001b[38;5;33mDense\u001b[0m)                â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            â”‚        \u001b[38;5;34m32,896\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ batch_normalization_21          â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            â”‚           \u001b[38;5;34m512\u001b[0m â”‚\n",
       "â”‚ (\u001b[38;5;33mBatchNormalization\u001b[0m)            â”‚                        â”‚               â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dropout_34 (\u001b[38;5;33mDropout\u001b[0m)            â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            â”‚             \u001b[38;5;34m0\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense_45 (\u001b[38;5;33mDense\u001b[0m)                â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             â”‚         \u001b[38;5;34m8,256\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dropout_35 (\u001b[38;5;33mDropout\u001b[0m)            â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             â”‚             \u001b[38;5;34m0\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense_46 (\u001b[38;5;33mDense\u001b[0m)                â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              â”‚            \u001b[38;5;34m65\u001b[0m â”‚\n",
       "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">174,081</span> (680.00 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m174,081\u001b[0m (680.00 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">173,313</span> (677.00 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m173,313\u001b[0m (677.00 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">768</span> (3.00 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m768\u001b[0m (3.00 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import tensorflow.keras.backend as K\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers, regularizers\n",
    "\n",
    "# ğŸ“Œ Define an Optimized Neural Network for USE Embeddings\n",
    "model = keras.Sequential([\n",
    "    layers.Dense(256, activation='relu', input_shape=(512,)),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.Dropout(0.3),\n",
    "\n",
    "    layers.Dense(128, activation='relu'),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.Dropout(0.3),\n",
    "\n",
    "    layers.Dense(64, activation='relu'),\n",
    "    layers.Dropout(0.2),\n",
    "\n",
    "    layers.Dense(1, activation='sigmoid')  # Binary classification output\n",
    "])\n",
    "\n",
    "\n",
    "def focal_loss(alpha=0.25, gamma=2.0):\n",
    "    def loss(y_true, y_pred):\n",
    "        bce = K.binary_crossentropy(y_true, y_pred)\n",
    "        p_t = y_true * y_pred + (1 - y_true) * (1 - y_pred)\n",
    "        return K.mean(alpha * K.pow(1 - p_t, gamma) * bce)\n",
    "    return loss\n",
    "\n",
    "\n",
    "class_weights = {0: 1.0, 1: 3.0}\n",
    "# Compile the model\n",
    "model.compile(optimizer=keras.optimizers.Adam(learning_rate=0.001),\n",
    "              loss=keras.losses.BinaryCrossentropy(),\n",
    "              metrics=[keras.metrics.BinaryAccuracy()])\n",
    "\n",
    "# Print the model summary\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m925/925\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 6ms/step - binary_accuracy: 0.7196 - loss: 0.8136 - val_binary_accuracy: 0.7155 - val_loss: 0.5851\n",
      "Epoch 2/20\n",
      "\u001b[1m925/925\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6ms/step - binary_accuracy: 0.7500 - loss: 0.7292 - val_binary_accuracy: 0.7276 - val_loss: 0.5677\n",
      "Epoch 3/20\n",
      "\u001b[1m925/925\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6ms/step - binary_accuracy: 0.7840 - loss: 0.6500 - val_binary_accuracy: 0.7103 - val_loss: 0.6138\n",
      "Epoch 4/20\n",
      "\u001b[1m925/925\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6ms/step - binary_accuracy: 0.7950 - loss: 0.6059 - val_binary_accuracy: 0.7155 - val_loss: 0.6456\n",
      "Epoch 5/20\n",
      "\u001b[1m925/925\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - binary_accuracy: 0.8068 - loss: 0.5886 - val_binary_accuracy: 0.7366 - val_loss: 0.5940\n",
      "Epoch 6/20\n",
      "\u001b[1m925/925\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - binary_accuracy: 0.8205 - loss: 0.5544 - val_binary_accuracy: 0.7293 - val_loss: 0.6133\n",
      "Epoch 7/20\n",
      "\u001b[1m925/925\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - binary_accuracy: 0.8307 - loss: 0.5227 - val_binary_accuracy: 0.7219 - val_loss: 0.6248\n",
      "Epoch 8/20\n",
      "\u001b[1m925/925\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - binary_accuracy: 0.8355 - loss: 0.5108 - val_binary_accuracy: 0.7248 - val_loss: 0.6051\n",
      "Epoch 9/20\n",
      "\u001b[1m925/925\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - binary_accuracy: 0.8419 - loss: 0.4998 - val_binary_accuracy: 0.7184 - val_loss: 0.6457\n",
      "Epoch 10/20\n",
      "\u001b[1m925/925\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - binary_accuracy: 0.8443 - loss: 0.4729 - val_binary_accuracy: 0.7304 - val_loss: 0.6339\n",
      "Epoch 11/20\n",
      "\u001b[1m925/925\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - binary_accuracy: 0.8455 - loss: 0.4670 - val_binary_accuracy: 0.7314 - val_loss: 0.6786\n",
      "Epoch 12/20\n",
      "\u001b[1m925/925\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - binary_accuracy: 0.8459 - loss: 0.4629 - val_binary_accuracy: 0.7252 - val_loss: 0.6657\n",
      "Epoch 13/20\n",
      "\u001b[1m925/925\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - binary_accuracy: 0.8549 - loss: 0.4410 - val_binary_accuracy: 0.7276 - val_loss: 0.6727\n",
      "Epoch 14/20\n",
      "\u001b[1m925/925\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - binary_accuracy: 0.8513 - loss: 0.4488 - val_binary_accuracy: 0.7368 - val_loss: 0.6781\n",
      "Epoch 15/20\n",
      "\u001b[1m925/925\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - binary_accuracy: 0.8543 - loss: 0.4345 - val_binary_accuracy: 0.7141 - val_loss: 0.6749\n",
      "Epoch 16/20\n",
      "\u001b[1m925/925\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - binary_accuracy: 0.8610 - loss: 0.4123 - val_binary_accuracy: 0.7184 - val_loss: 0.6996\n",
      "Epoch 17/20\n",
      "\u001b[1m925/925\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - binary_accuracy: 0.8602 - loss: 0.4114 - val_binary_accuracy: 0.7153 - val_loss: 0.6918\n",
      "Epoch 18/20\n",
      "\u001b[1m925/925\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - binary_accuracy: 0.8601 - loss: 0.4121 - val_binary_accuracy: 0.7170 - val_loss: 0.7112\n",
      "Epoch 19/20\n",
      "\u001b[1m925/925\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - binary_accuracy: 0.8625 - loss: 0.4055 - val_binary_accuracy: 0.7283 - val_loss: 0.6581\n",
      "Epoch 20/20\n",
      "\u001b[1m925/925\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - binary_accuracy: 0.8625 - loss: 0.4002 - val_binary_accuracy: 0.7283 - val_loss: 0.7058\n"
     ]
    }
   ],
   "source": [
    "# ğŸš€ Early Stopping Callback\n",
    "early_stopping = keras.callbacks.EarlyStopping(\n",
    "    monitor=\"val_loss\",  # Track validation loss\n",
    "    patience=5,          # Stop if val_loss doesn't improve for 5 epochs\n",
    "    restore_best_weights=True  # Restore best model weights\n",
    ")\n",
    "\n",
    "# Convert validation data to embeddings\n",
    "X_val_embeddings = get_embeddings(df_val[\"text\"].tolist())\n",
    "y_val = df_val[\"label_sexist\"].values\n",
    "\n",
    "# ğŸ“Œ Train the Model with Validation\n",
    "history = model.fit(\n",
    "    X_train_embeddings, y_train,\n",
    "    epochs=20,\n",
    "    batch_size=32,\n",
    "    validation_data=(X_val_embeddings, y_val),\n",
    "    verbose=1,\n",
    "    class_weight=class_weights\n",
    "    # callbacks=[early_stopping]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m267/267\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.70      0.73      4442\n",
      "           1       0.70      0.75      0.72      4085\n",
      "\n",
      "    accuracy                           0.73      8527\n",
      "   macro avg       0.73      0.73      0.73      8527\n",
      "weighted avg       0.73      0.73      0.73      8527\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAhAAAAGdCAYAAABDxkoSAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjEsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvc2/+5QAAAAlwSFlzAAAPYQAAD2EBqD+naQAAM5lJREFUeJzt3Q18zXX/+PH3sM3txsw2crdS7nJ/O+JqJUsK0SWVu9yFmctWaIVENRci96ur3PyvyE3XhVC0MC6ZiEbICkNik7AxbGPn//h8+p3Tztf4nm9t7dDr2eP7ODvf7+d8z+f0iL17v9+fz/Gw2Ww2AQAAsKCIlcEAAAAKAQQAALCMAAIAAFhGAAEAACwjgAAAAJYRQAAAAMsIIAAAgGUEEAAAwDICCAAAYFkxcRPZZ48W9hQAt9Oqft/CngLglnad2nrb/E7y9L9b7kRuE0AAAOA2cq4X9gzcHiUMAABgGRkIAACMbDmFPQO3RwABAIBRDgGEGQIIAAAMbGQgTNEDAQAALCMDAQCAESUMUwQQAAAYUcIwRQkDAABYRgYCAAAjNpIyRQABAIARJQxTlDAAAIBlZCAAADBiFYYpAggAAAzYSMocJQwAAGAZGQgAAIwoYZgigAAAwIgShilKGAAA5LUPRH4dFsybN0/q168vPj4++ggJCZHPPvvMcf3q1asSHh4u5cuXl9KlS0u3bt0kNTXV6R4nTpyQjh07SsmSJSUgIEBGjhwp165dcxoTHx8vjRs3Fm9vb6lRo4YsXLhQrCKAAADATVSuXFkmTZoku3fvlq+//loeeugh6dy5sxw4cEBfj4yMlDVr1siKFStky5YtcurUKenatavj9devX9fBQ1ZWlmzfvl0WLVqkg4Nx48Y5xiQnJ+sxoaGhkpiYKCNGjJABAwbIhg0bLM3Vw2az2cQNZJ89WthTANxOq/p9C3sKgFvadWprgd4/87vN+XYv79qhf+j1fn5+MmXKFHnqqaekQoUKsmTJEv2zcujQIaldu7YkJCRIy5Ytdbbi8ccf14FFYGCgHhMbGyujR4+Wn3/+Wby8vPTP69atk/379zveo0ePHnLhwgVZv369y/MiAwEAQF5NlPl0ZGZmSnp6utOhzplR2YSlS5dKRkaGLmWorER2dra0a9fOMaZWrVpStWpVHUAo6rFevXqO4EEJCwvT72nPYqgxue9hH2O/h6sIIAAAKEAxMTHi6+vrdKhzN/Ptt9/q/gbVnzB48GBZuXKl1KlTR1JSUnQGoWzZsk7jVbCgrinqMXfwYL9uv3arMSrIuHLlisufi1UYAAAU4CqM6OhoiYqKcjqngoObqVmzpu5NSEtLk48//lj69Omj+x3cDQEEAAAFuA+Et7f3LQMGI5VlUCsjlCZNmsiuXbtkxowZ8vTTT+vmSNWrkDsLoVZhBAUF6Z/V486dO53uZ1+lkXuMceWGeq5WfZQoUcLleVLCAADAjeX8Xx+FCiY8PT1l48aNjmtJSUl62abqkVDUoyqBnDlzxjEmLi5OBweqDGIfk/se9jH2e7iKDAQAAAY2m7X9G/Kz3NGhQwfdGHnx4kW94kLt2aCWWKreif79++tyiFqZoYKCiIgI/YtfrcBQ2rdvrwOFXr16yeTJk3W/w5gxY/TeEfYsiOqrmD17towaNUr69esnmzZtkuXLl+uVGVYQQAAA4CY7UZ45c0Z69+4tp0+f1gGD2lRKBQ+PPPKIvj59+nQpUqSI3kBKZSXU6om5c+c6Xl+0aFFZu3atDBkyRAcWpUqV0j0UEyZMcIwJDg7WwYLaU0KVRtTeE++//76+lxXsAwG4MfaBAApnH4iriWvz7V7FGz4udyIyEAAAGPFlWqYIIAAAMOLLtEwRQAAAYGTxS7D+iljGCQAALCMDAQCAESUMUwQQAAAY0URpihIGAACwjAwEAABGlDBMEUAAAGBECcMUJQwAAGAZGQgAAIzIQJgigAAAwE2+jfN2QgkDAABYRgYCAAAjShimCCAAADBiGacpAggAAIzIQJiiBwIAAFhGBgIAACNKGKYIIAAAMKKEYYoSBgAAsIwMBAAARpQwTBFAAABgRAnDFCUMAABgGRkIAACMyECYIoAAAMCIHghTlDAAAIBlZCAAADCihGGKAAIAACNKGKYIIAAAMCIDYYoeCAAAYBkZCAAAjChhmCKAAADAiBKGKUoYAADAMgIIAADyykDk12FBTEyMNGvWTMqUKSMBAQHSpUsXSUpKclw/duyYeHh45HmsWLHCMS6v60uXLnV6r/j4eGncuLF4e3tLjRo1ZOHChVamSgABAMANbLb8OyzYsmWLhIeHy44dOyQuLk6ys7Olffv2kpGRoa9XqVJFTp8+7XS8/vrrUrp0aenQoYPTvRYsWOA0TgUjdsnJydKxY0cJDQ2VxMREGTFihAwYMEA2bNjg8lzpgQAAwE2sX7/e6bnKCqhMxO7du6Vt27ZStGhRCQoKchqzcuVK6d69uw4icitbtuwNY+1iY2MlODhY3n77bf28du3asm3bNpk+fbqEhYW5NFcyEAAAFGAJIzMzU9LT050Odc4VaWlp+tHPzy/P6yqwUBmE/v3733BNZTL8/f2lefPmMn/+fLHlyoYkJCRIu3btnMarwEGddxUBBAAABRhAxMTEiK+vr9OhzplPIUeXFlq3bi33339/nmM++OADnT1o1aqV0/kJEybI8uXLdRmkW7duMnToUJk1a5bjekpKigQGBjq9Rj1Xwc2VK1dc+ldECQMAgAIUHR0tUVFRTudU46IZlUHYv3+/Li3kRf2iX7JkiYwdO/aGa7nPNWrUSPdQTJkyRYYPHy75hQwEAAB5bSSVT4e3t7f4+Pg4HWYBxLBhw2Tt2rWyefNmqVy5cp5jPv74Y7l8+bL07t3b9OO0aNFCTp486SidqN6I1NRUpzHquZpbiRIlXPpXRAYCAAA32UjKZrNJRESEboxUyyxVo+PNqPJFp06dpEKFCqb3VX0S5cqVcwQuISEh8umnnzqNUeUOdd5VBBAAABhZXH6ZX1TZQpUlVq9erfeCUL0KiuqbyJ0ZOHz4sGzduvWGIEBZs2aNzia0bNlSihcvrgODt956S1566SXHmMGDB8vs2bNl1KhR0q9fP9m0aZPumVi3bp3LcyWAAADATcybN08/Pvjggzfs6dC3b1/Hc7WqQpU21B4RRp6enjJnzhyJjIzUGQ21SdS0adNk4MCBjjEqs6GCBTVmxowZ+l7vv/++y0s4FQ9b7nUdhSj77NHCngLgdlrV/+0vDAC/2XVqa4He/8qCUfl2rxLPT5Y7ERkIAACM+DItU6zCAAAAlpGBAADASC3BxC0RQAAAYGDLcYv2QLdGCQMAAFhGBgIAACOaKE0RQAAAYEQPhClKGAAAwDIyEAAAGNFEaYoAAgAAI3ogTBFAAABgRABhih4IAABgGRkIAACM3ON7Jt0aAcQdZunKtbJs5To5dTpVP68RXE0GP/+stAlppp+vWP2prIuLl++SDkvG5Suyff0K8SlT2vH6n06nSuzCJbJz9145+8t5qeDvJ4+HPSQv9OmhvyLW7suvdsuc9/8th5NPiLe3pzRpUE9GRgyUuyoGFsKnBsw1atFAeg3tIbXq1ZQKQf7yUr9XZMv6bY7rA198Xtp3fkgCKwVIdtY1OfRtksyd9C858M13jjHPD+8lD7QLkfvq1pDsrGx5qHbHm76fbzkfWRw3X98vtNZjcin9UoF/RuQjShimKGHcYYIq+Evk4Odl+fxZsuyDmdK8SQOJeHmCHD56XF+/ejVTHmjRVAb27pHn65OP/6i3cB03MkJWfRgro4e/IMtXfSrvvLvQMebkqRSJePl1ad6koXy8cLa8O+1NuZCWJiNemfinfU7AqhIli8v3B47I5Fem53n9xNEfZcqr78gzD/WVgV3C5dSPKTL7o7elrJ+vY4ynVzH5Ys1m+c+i1abvN+bt0XL4u6P5+hkAd0IG4g7z4AMtnZ7/44W+OiOx98AhqXF3Nen19JP6/M49+/J8/QMtm+rDrspdFSX5xElZvmqdjBw2UJ87mPSD5FzPkeGDekuRIr/GoH2f6aYDlexr18SzGP9Zwf1s3/yVPm5mw8ovnJ6/M362dHn2cbm3zj2ya9sefe69qQv04+PdH73le3Xr3VnK+JSW96cvktYPO/+ZxG2CZZymyEDcwa5fvy6ffhEvV65elYb31/rd97mUkSE+Zco4ntepea94FPGQlevi9HtcvJQhazZskpZNGxI84I5QzLOYPNmzk1xMuyjfHzxi6bXB91aTAZF95bV/vCk5pMFv750o8+u4Q1n+2/7s2bMyf/58SUhIkJSUFH0uKChIWrVqJX379pUKFSoUxDxhwfdHkuW5F6IkKytLSpYoITPeGiv3BFf7Xfc6cfKULPn4E3lp2ADHucqVguS96W/Ki2NjZMKUmXL9eo40uL+2zJs6IR8/BfDnU/0Nb857TYqXKC5nU3+RYT1elLRzaS6/3tPLU96Y+5rMnDhXUn86I3dVrVSg8wVumwzErl275L777pOZM2eKr6+vtG3bVh/qZ3WuVq1a8vXXX5veJzMzU9LT050OdQ75I7hqZfnPwjmy5L13pHuXjvLqm2/LkeRfeyCsSP35rLwQNUbah7aRpzp1cJw/+8s5Gf/PmdK5QztZ+v4MWThnsnh6FpOoMW+Kjc5l3Ma+/vIbee6R/tK/01BJiN8pb737upQrX9bl14dHD5Jjh4/LZ/+NK9B54k8qYeTXcYeylIGIiIiQv//97xIbGyseHh5O19QvjsGDB+sxKjtxKzExMfL66687nRszcriMG/UPK9PBTajVElUr//p/PnVr3SsHDn0vH65YLa+NGu7yPc78/Iv0i3hZGtarI+NHO7/uo/+sldKlSsqL4f0d5yaNGyntnuwt+w4c0tkI4HZ09cpVOXnsJ33s33NQ/rNtiXR+pqMsnL3Ypdc3e6Cx3FPrbnmo49/0c/vfk3H7P5EFM//t6KGA+7NRfsrfAGLv3r2ycOHCG4IHRZ2LjIyURo0amd4nOjpaoqKinM4VufiTlanAgpwcm2RlZVvKPKjgoU7NGvLGK5GORkm7q5mZN5wrWqTor+9FBgJ3kCJFPMTT28vl8aMGjJXixb0dz+s0rCXjpkfLoCcjdFAC/GUDCNXrsHPnTl2qyIu6Fhhovg+At7e3PnLLzjprZSq4ienzFkibkKZSMTBAMi5flnWfx8uub/bJu9PecJQf1P4OqrdB+eHIMSlVsoRUDAoQX58yOnh4fthoqRQUoPsezl/4rf7rX95PP7Zt1Uz+37KVMm/+YnnskQf1fhIz3l2oX1P7vnsK6ZMDt1aiZAmpEnyX43mlKhX1fg5pF9Il7Vy69PtHL9n6+Ze690Et3fz780/q/SI2rtnseE3gXQHiW9ZHgu4KlCJFi+rXKz8m/yRXLl+Rn47/+ufKzvf/loAm/3CcfSBuN3dw6aFQAoiXXnpJBg0aJLt375aHH37YESykpqbKxo0b5V//+pdMnTo13yYH685duCCvTJwqP/9yTsqUKiX31QjWwUOr5o319WWrPtW/+O36hI/Uj2+8EiVdOj4iCTu/0cGFOh7u0svp3vu//Ew/tmjSUP45fpQsWPyxzF/ysZTw9tZli9hpb0hxQ2AIuIvaDWrKu/+Z6Xge9XqEfly77DOJefltqV6jmnT8+6M6eEg7ny4H9x7SmYOj3x9zvGbwS/3l8ad/6wdSG0UpL3QbLnsSEv/Uz4MCdgevnsgvHjaLXW/Lli2T6dOn6yBCLeFTihYtKk2aNNFlie7du/+uiWSfZcMVwKhV/b6FPQXALe06tbVA758x4bl8u1epca710NzxyziffvppfWRnZ+slnYq/v7/TNscAAODO9rt3/VEBQ8WKFfN3NgAAuANWYZhi20AAAIxoojTFVtYAAMAyMhAAABixCsMUAQQAAEaUMExRwgAAAJaRgQAAwIDvwjBHAAEAgBElDFOUMAAAcBMxMTHSrFkzKVOmjAQEBEiXLl0kKSnJacyDDz6ov8Ay96G+DTu3EydOSMeOHaVkyZL6PiNHjpRr1645jYmPj5fGjRvr76aqUaOG/rJMKwggAADIKwORX4cFW7ZskfDwcNmxY4fExcXpXZ/bt28vGRkZTuMGDhwop0+fdhyTJ092XFNfM6GCh6ysLNm+fbssWrRIBwfjxo1zjElOTtZjQkNDJTExUUaMGCEDBgyQDRs2uDxXShgAALjJMs7169c7PVe/+FUGQX3/VNu2bR3nVWZBfUN2Xj7//HM5ePCgfPHFF/pLLxs2bCgTJ06U0aNHy/jx48XLy0tiY2MlODhY3n77bf2a2rVry7Zt2/R3XYWFhbk0VzIQAAAUYAYiMzNT0tPTnQ51zhVpaWn60c/Pz+n84sWL9fdQ3X///RIdHS2XL192XEtISJB69eo5vjFbUUGBet8DBw44xrRr187pnmqMOu8qAggAAAq4r8HX19fpUOfM5OTk6NJC69atdaBg9+yzz8qHH34omzdv1sHDv//9b+nZs6fjekpKilPwoNifq2u3GqOCjCtXrrj0uShhAABgYMvHVRjR0dESFRXldE41LppRvRD79+/XpYXcBg0a5PhZZRrUF1s+/PDDcuTIEbnnnnvkz0IAAQCAUT4GEN7e3i4FDLkNGzZM1q5dK1u3bpXKlSvfcmyLFi304+HDh3UAoXojdu7c6TQmNTVVP9r7JtSj/VzuMT4+PlKiRAmX5kgJAwAAN2Gz2XTwsHLlStm0aZNudDSjVlEoKhOhhISEyLfffitnzpxxjFErOlRwUKdOHceYjRs3Ot1HjVHnXUUGAgAAo0LaiTI8PFyWLFkiq1ev1ntB2HsWVN+EygyoMoW6/thjj0n58uVl3759EhkZqVdo1K9fX49Vyz5VoNCrVy+9vFPdY8yYMfre9kyI2jdi9uzZMmrUKOnXr58OVpYvXy7r1q1zea4eNhXuuIHss0cLewqA22lVv29hTwFwS7tObS3Q+18c2iHf7lVm7mcuj1WbQuVlwYIF0rdvX/nxxx91w6TqjVB7Q1SpUkWefPJJHSCoDIPd8ePHZciQIXqzqFKlSkmfPn1k0qRJUqzYb3kDdU0FH2rJpyqTjB07Vr+Hy3MlgADcFwEE8NcKIG4nlDAAADDiuzBMEUAAAGDgJsl5t8YqDAAAYBkZCAAAjChhmCKAAADAiADCFAEEAAAFuJX1nYoeCAAAYBkZCAAAjMhAmCKAAADAqHB2sr6tUMIAAACWkYEAAMCAJkpzBBAAABgRQJiihAEAACwjAwEAgBFNlKYIIAAAMKAHwhwlDAAAYBkZCAAAjChhmCKAAADAgBKGOQIIAACMyECYogcCAABYRgYCAAADGxkIUwQQAAAYEUCYooQBAAAsIwMBAIABJQxzBBAAABgRQJiihAEAACwjAwEAgAElDHMEEAAAGBBAmCOAAADAgADCHD0QAADAMjIQAAAY2TwKewZujwACAAADShjmKGEAAADLCCAAADCw5Xjk22FFTEyMNGvWTMqUKSMBAQHSpUsXSUpKclw/d+6cRERESM2aNaVEiRJStWpVGT58uKSlpTndx8PD44Zj6dKlTmPi4+OlcePG4u3tLTVq1JCFCxdamisBBAAAeZQw8uuwYsuWLRIeHi47duyQuLg4yc7Olvbt20tGRoa+furUKX1MnTpV9u/fr3/pr1+/Xvr373/DvRYsWCCnT592HCoYsUtOTpaOHTtKaGioJCYmyogRI2TAgAGyYcMGl+fqYbPZbOIGss8eLewpAG6nVf2+hT0FwC3tOrW1QO9/qlVovt2r0vbNv/u1P//8s85EqMCibdu2eY5ZsWKF9OzZUwcZxYr92tqoMg4rV650ChpyGz16tKxbt04HIXY9evSQCxcu6IDEFWQgAAAwsNk88u3IzMyU9PR0p0Odc4W9NOHn53fLMT4+Po7gwU5lMvz9/aV58+Yyf/58yZ0vSEhIkHbt2jmNDwsL0+ddRQABAEABljBiYmLE19fX6VDnzOTk5OjSQuvWreX+++/Pc8zZs2dl4sSJMmjQIKfzEyZMkOXLl+sySLdu3WTo0KEya9Ysx/WUlBQJDAx0eo16roKbK1euuPTviGWcAAAUoOjoaImKinI6pxoXzagMgioxbNu2Lc/r6pe96mOoU6eOjB8/3una2LFjHT83atRIlzemTJmiGy7zCxkIAAAKcBWGt7e3LjHkPswCiGHDhsnatWtl8+bNUrly5RuuX7x4UR599FG9WkP1Onh6et7yfi1atJCTJ086SidBQUGSmprqNEY9V3NTqztcQQYCAACDwlpeYLPZ9DJNFRSoZZbBwcF5Zh5Uv4IKQj755BMpXry46X3VSoty5co5ApeQkBD59NNPncaococ67yoCCAAADKzu35BfVNliyZIlsnr1ap1dUL0KiuqbUJkBFTyoZZ2XL1+WDz/80NGUqVSoUEGKFi0qa9as0dmEli1b6uBCBQZvvfWWvPTSS473GTx4sMyePVtGjRol/fr1k02bNumeCbUyw1Us4wTcGMs4gcJZxnm8sfMKhT+i2p4vXB6rll/mRe3p0LdvX52VUHs35EXt7VC9enW9DFP1XRw+fFhnNNQmUUOGDJGBAwdKkSK/dS6oe0VGRsrBgwd1mUT1Taj3cHmuBBCA+yKAAAongDjW8JF8u1f1xDi5E1HCAADAwD3+19q9sQoDAABYRgYCAAA3aaK8nRBAAABgoLagxq1RwgAAAJaRgQAAwMDq13D/FRFAAABgkEMJwxQlDAAAYBkZCAAADGiiNEcAAQCAAcs4zRFAAABgwE6U5uiBAAAAlpGBAADAgBKGOQIIAAAMWMZpjhIGAACwjAwEAAAGLOM0RwABAIABqzDMUcIAAACWkYEAAMCAJkpzBBAAABjQA2GOEgYAALCMDAQAAAY0UZojgAAAwIAeiNsogChRqU1hTwFwO5e/X13YUwD+kuiBMEcPBAAAuH0zEAAAuAtKGOYIIAAAMKCH0hwlDAAAYBkZCAAADChhmCOAAADAgFUY5ihhAAAAy8hAAABgkFPYE7gNEEAAAGBgE0oYZihhAADgJmJiYqRZs2ZSpkwZCQgIkC5dukhSUpLTmKtXr0p4eLiUL19eSpcuLd26dZPU1FSnMSdOnJCOHTtKyZIl9X1Gjhwp165dcxoTHx8vjRs3Fm9vb6lRo4YsXLjQ0lwJIAAAMMix5d9hxZYtW3RwsGPHDomLi5Ps7Gxp3769ZGRkOMZERkbKmjVrZMWKFXr8qVOnpGvXro7r169f18FDVlaWbN++XRYtWqSDg3HjxjnGJCcn6zGhoaGSmJgoI0aMkAEDBsiGDRtcnquHzeYe3zlWzOuuwp4C4Hb4Lgwgb17Vmxbo/TcFds+3ez2Uuvx3v/bnn3/WGQQVKLRt21bS0tKkQoUKsmTJEnnqqaf0mEOHDknt2rUlISFBWrZsKZ999pk8/vjjOrAIDAzUY2JjY2X06NH6fl5eXvrndevWyf79+x3v1aNHD7lw4YKsX7/epbmRgQAAII8eiPw6MjMzJT093elQ51yhAgbFz89PP+7evVtnJdq1a+cYU6tWLalataoOIBT1WK9ePUfwoISFhen3PXDggGNM7nvYx9jv4QoCCAAACrivwdfX1+lQ58zk5OTo0kLr1q3l/vvv1+dSUlJ0BqFs2bJOY1WwoK7Zx+QOHuzX7dduNUYFGVeuXHHpc7EKAwCAAlzGGR0dLVFRUU7nVOOiGdULoUoM27ZtE3dEAAEAQAEu4/T29nYpYMht2LBhsnbtWtm6datUrlzZcT4oKEg3R6pehdxZCLUKQ12zj9m5c6fT/eyrNHKPMa7cUM99fHykRIkSLs2REgYAAG7CZrPp4GHlypWyadMmCQ4OdrrepEkT8fT0lI0bNzrOqWWeatlmSEiIfq4ev/32Wzlz5oxjjFrRoYKDOnXqOMbkvod9jP0eriADAQCAm+xEGR4erldYrF69Wu8FYe9ZUH0TKjOgHvv3769LIqqxUgUFERER+he/WoGhqGWfKlDo1auXTJ48Wd9jzJgx+t72TMjgwYNl9uzZMmrUKOnXr58OVpYvX65XZriKZZyAG2MZJ1A4yzg/DeyRb/d6LHWpy2M9PPIunSxYsED69u3r2EjqxRdflI8++kiv5lCrJ+bOnesoTyjHjx+XIUOG6M2iSpUqJX369JFJkyZJsWK/5Q3UNbWnxMGDB3WZZOzYsY73cGmuBBCA+yKAAP5aAcTthBIGAAAGfBeGOQIIAAAMcogfTLEKAwAAWEYGAgAAgxxKGKYIIAAAMHCL1QVujgACAAA32QfidkIPBAAAsIwMBAAABjk32dAJvyGAAADAgB4Ic5QwAACAZWQgAAAwoInSHAEEAAAG7ERpjhIGAACwjAwEAAAG7ERpjgACAAADVmGYo4QBAAAsIwMBAIABTZTmCCAAADBgGac5AggAAAzogTBHDwQAALCMDAQAAAb0QJgjgAAAwIAeCHOUMAAAgGVkIAAAMCADYY4AAgAAAxs9EKYoYQAAAMvIQAAAYEAJwxwBBAAABgQQ5ihhAAAAy8hAAABgwFbW5gggAAAwYCdKcwQQAAAY0ANhjh4IAABgGQEEAAB5ZCDy67Bi69at8sQTT0ilSpXEw8NDVq1a5XRdncvrmDJlimNM9erVb7g+adIkp/vs27dP2rRpI8WLF5cqVarI5MmTxSpKGAAAuEkTZUZGhjRo0ED69esnXbt2veH66dOnnZ5/9tln0r9/f+nWrZvT+QkTJsjAgQMdz8uUKeP4OT09Xdq3by/t2rWT2NhY+fbbb/X7lS1bVgYNGuTyXAkgAABwEx06dNDHzQQFBTk9X716tYSGhsrdd9/tdF4FDMaxdosXL5asrCyZP3++eHl5Sd26dSUxMVGmTZtmKYCghAEAQB6rMPLryMzM1P/Xn/tQ5/6o1NRUWbdunc5AGKmSRfny5aVRo0a6vHHt2jXHtYSEBGnbtq0OHuzCwsIkKSlJzp8/7/L7E0AAAFCAPRAxMTHi6+vrdKhzf9SiRYt0psFY6hg+fLgsXbpUNm/eLC+88IK89dZbMmrUKMf1lJQUCQwMdHqN/bm65ipKGAAAFKDo6GiJiopyOuft7f2H76tKEM8995xuhMwt93vVr19fZxpUIKGClvx4XzsCCAAACrCJ0tvbO19/cSv/+9//dMlh2bJlpmNbtGihSxjHjh2TmjVr6t4IVf7Izf78Zn0TeaGEAQCAQY7Y8u0oCB988IE0adJEr9gwoxokixQpIgEBAfp5SEiIXi6anZ3tGBMXF6eDi3Llyrk8BwIIAADcxKVLl/QvfHUoycnJ+ucTJ044xqgmzBUrVsiAAQNueL1qkHznnXdk7969cvToUb3iIjIyUnr27OkIDp599lld1lDNlwcOHNBZjBkzZtxQZjFDCQMAADfZyvrrr7/WyzLt7L/U+/TpIwsXLtQ/qwZJm80mzzzzzA2vV6USdX38+PF6pUdwcLAOIHIHB6qJ8/PPP5fw8HCdxfD395dx48ZZWsKpeNjULNxAMa+7CnsKgNu5/P3qwp4C4Ja8qjct0PtPqPZcvt1r3PHFciciAwEAgAFfpmWOHggAAGAZGQgAAAzUDpK4NQIIAAAMCmr55Z2EEgYAALCMDAQAAAbkH8wRQAAAYMAqDHOUMAAAgGVkIAAAMKCJ0hwBBAAABoQP5ihhAAAAy8hAAABgQBOlOQIIAAAM6IEwRwABAIAB4YM5eiAAAIBlZCAAADCgB8IcAQQAAAY2ihimKGEAAADLyEAAAGBACcMcAQQAAAYs4zRHCQMAAFhGBgIAAAPyD+bIQNyB2jzQQlatXCgnju2Wa1k/SadOYTeMGf/aS/Lj8T1yMe2wbPhsqdSoEey4Vq1aZXnv3anyQ1KCvp703Zfy2rgXxdPTM8/3u+ee6nL+lyQ5e+ZggX4u4I9YtuYL6Tr4ZWn5ZH99PDfiNfnfrkTH9cysLHlj9gJ54KkXpHnnfhI54R05ez7thvus+nyLvk+Tx/vK37oP0a/JfY9Xp8bKky+MloYdesnw8dP+tM+H/C9h5NdxpyKAuAOVKlVS9u07KBH/eDXP6yNfGirDwvvJ0GEvS6sHnpCMy5fl07WLxdvbW1+vVbOGFClSRIaGj5b6DR+SF0eOl0EDe8mbE1++4V7FihWTD/89R7Zt+6rAPxfwRwRW8JMR/XrIstlvytJZb0iLBnX1L/jDx07q65NjP5QtO76Rt8cMlwVTx8qZc+clcsJ0p3ss+s+nMmvhCunf/QlZ9d4/5b1J0dK6SX3H9es5OVLcy0ue6xwmLRvd/6d/RuDPRAnjDrR+w2Z93MzwiAHyVswMWbPmc/287/P/kFMnE6Vz5zBZvvwT2fB5vD7skpNPyLT7YuWFQb1l1MsTne41ccIoSUo6Ips2bZOQkKYF+KmAP+bBlo2dng9/vrssW/uF7Dt0WAcX/90QL/98OVxaNKyrr0+MekE6Dxwpe7/7QRrUvlfSLmbI7EUrZNbrLzoFBzXvrur4uWTx4jJ2eD/98zcHv5eLly7/aZ8P+YtVGObIQPzFBAdXlYoVA2Xjpm2Oc+npF2Xnzm+kZYsmN32dr6+PnDt/welc6IOtpVvXxyVi+CsFOmcgv12/niOfxSfIlcxMaVC7hhz8IVmuXbvuFBjcXbWSVAwoL3u/O6yfJ+z5VnJybHLm7HnpNGCkPPzcMHnxjZmScuaXQvwkKMiNpPLrnzsVGYi/mKDAAP2Ymvqz0/nUM2clKOjXa3n1OIQPfV5Gjf4t++DnV04+eH+69OkbIRcvXirgWQP54/vkE9JzxHjJysqWkiWKyzvjIuWeapXl0JHj4ulZTHxKl3IaX76sr5w992vgfDLljOTYcuRfS1fLy0N6S+lSJXQ5Y2B0jPw3dpJ+Pe4cZCAKIQPx448/Sr9+v6bwbiYzM1PS09OdDpvtzo3SbmeVKgXJujUfysf/WSsfzF/iOP9u7GRZumyl/I/eB9xGgitXko/nviWLZ06Q7o8/LGOmxsqR47/2QJix5dh0liJ6aG9p3bS+LmtMjh4mJ06lyM69NBDjryffA4hz587JokWLbjkmJiZGfH19nQ5bzsX8ngrykJJ6Rj8GBlZwOh8Y4C8pKb9es1Olji/iVkjCjt0yeMioG8oXUZGD5erl4/r413tTpWxZX/1z3z5P/wmfBLBOZQmq3hUkde8N1g2V9wVXlQ9XbRB/v7KSnX1N0i9lOI3/5UKavqbYH++uepfjul9ZHynrU0ZOnzn7J38SFDRKGOYs59w++eSTW14/evSo6T2io6MlKirK6Vy58rWsTgW/g2qIPH06VR4KfUD27j2gz5UpU1qaN28kse/9P6fMgwoe9uzZJ/0HRN6QIXqgbScpWrSo43mnJ8L06o42f+ssP/2U8id+IuD3U/9dZ2VnS517g6VYsaLy1TcH5JE2zfW15B9Pyekzv+geCaVR3fv047GTpyWoQnn9c1r6JbmQflEqBfoX4qdAQaCEUQABRJcuXcTDw+OWJQd1/VbUckH7kkFXXwNryzhz7+sQXL2qNGhQV86dOy8//nhKZs56X16JHi4/HD4qx479KK+PHymnTqXK6tUbHMHDxriP5cSJk7rvocL//WWZu3fi0KFfG8vsmjRuIDk5OXLgQNKf9jkBK96Zv1QeaNZAKlbwl4wrV+TTzdtl177vJPbN0VKmVEnpGvagTHnvQ/EtU0r/GYqZs0iXKdShVK9cUUJDmsg/5/1bXvtHfylVqoTMmL9Ml0WaNajjeB9VEsm+dk3SL2ZIxuUrcujIMX2+1j3VC+2zA24RQFSsWFHmzp0rnTt3zvN6YmKiNGly825+FLymTRrIxi8+djx/e+p4/bjo/y3X2YQpU+fqvyBj506WsmV95Msvd0nHJ3rq3hSl3cNt5d57g/WhNqPKrZjXb+lb4HZy7kK6vDolVn4+d0HKlCwp9wZX0cFDqyb19PVRg3uKRxEPiZw4Q5czWjWtJ2OGPe90j7dGDpbJ734oQ8dNkSIeRaRp/Vr6Hp7FfvurdOjYKXIq9beSxt+H/rofy7cbFv9pnxV/XA59eaY8bBa7Fzt16iQNGzaUCRMm5Hl979690qhRI/1/o1bwiwm40eXvVxf2FAC35FW9YPed6Vmta77d68Pj/3V57NatW2XKlCmye/duOX36tKxcuVJn/u369u17Q59hWFiYrF+/3qkXMSIiQtasWaM3BezWrZvMmDFDSpcu7Rizb98+CQ8Pl127dkmFChX0+FGjnHvd8r2JcuTIkdKqVaubXq9Ro4Zs3nzzTYwAAEDeMjIypEGDBjJnzpybjBB59NFHdXBhPz766COn688995wcOHBA4uLiZO3atTooGTRokOO6WvnYvn17qVatmg5UVMAyfvx4ee+996RASxht2rS55fVSpUrJ3/72N6u3BQDAbRTWd1h06NBBH7eiegiDgoLyvPbdd9/pbITKLDRt+muWZtasWfLYY4/J1KlTpVKlSrJ48WLJysqS+fPni5eXl9StW1e3H0ybNs0p0DDDTpQAANxGyzjj4+MlICBAatasKUOGDJFffvltN9SEhAQpW7asI3hQ2rVrp0sZX331lWNM27ZtdfCQuwySlJQk58+fd3kebJ0GAEAByszMdDSp32o1oitU+aJr164SHBwsR44ckVdeeUVnLFRQoJbWp6Sk6ODC+KWHfn5++pqiHtXrcwsMDHRcK1eunEtzIQMBAIBBTj4eMXlsnqjO/R49evTQixnq1aunmytVj4MqV6isxJ+NDAQAAAXYAxGdx+aJvyf7kJe7775b/P395fDhw/Lwww/r3ogzZ5x3Fb527ZpemWHvm1CPqampTmPsz2/WW5EXMhAAABRgD4S3t7f4+Pg4HfkVQJw8eVL3QKg9mpSQkBC5cOGCXl1ht2nTJr21QosWLRxj1MqM7Oxsxxi1YkP1VLhavlAIIAAAcBOXLl3SKyLUoSQnJ+ufT5w4oa+prRR27Nghx44dk40bN+pNHdX2CaoJUqldu7bukxg4cKDs3LlTvvzySxk2bJgufagVGMqzzz6rGyj79++vl3suW7ZM7xNhzJKYoYQBAICbfBfG119/LaGhoY7n9l/qffr0kXnz5ukNoNRGUirLoAICtZ/DxIkTnTIaapmmChpUScO+kdTMmTMd11UPxueff643klI7R6sSyLhx4ywt4fxdO1EWFHaiBG7ETpRA4exE+WTVJ/LtXitPrJE7ESUMAABgGSUMAADcZCfK2wkBBAAAbtIDcTuhhAEAACwjAwEAgEFBfIfFnYYAAgAAA3ogzFHCAAAAlpGBAADAwE22SHJrBBAAABiwCsMcAQQAAAY0UZqjBwIAAFhGBgIAAANWYZgjgAAAwIAmSnOUMAAAgGVkIAAAMKCEYY4AAgAAA1ZhmKOEAQAALCMDAQCAQQ5NlKYIIAAAMCB8MEcJAwAAWEYGAgAAA1ZhmCOAAADAgADCHAEEAAAG7ERpjh4IAABgGRkIAAAMKGGYI4AAAMCAnSjNUcIAAACWkYEAAMCAJkpzBBAAABjQA2GOEgYAALCMDAQAAAaUMMwRQAAAYEAJwxwlDAAAYBkBBAAAeewDkV//WLF161Z54oknpFKlSuLh4SGrVq1yXMvOzpbRo0dLvXr1pFSpUnpM79695dSpU073qF69un5t7mPSpElOY/bt2ydt2rSR4sWLS5UqVWTy5MliFQEEAAAGOTZbvh1WZGRkSIMGDWTOnDk3XLt8+bLs2bNHxo4dqx//+9//SlJSknTq1OmGsRMmTJDTp087joiICMe19PR0ad++vVSrVk12794tU6ZMkfHjx8t7771naa70QAAA4CY7UXbo0EEfefH19ZW4uDinc7Nnz5bmzZvLiRMnpGrVqo7zZcqUkaCgoDzvs3jxYsnKypL58+eLl5eX1K1bVxITE2XatGkyaNAgl+dKBgIAgNtUWlqaLlGULVvW6bwqWZQvX14aNWqkMwzXrl1zXEtISJC2bdvq4MEuLCxMZzPOnz/v8nuTgQAAwMBq6eFWMjMz9ZGbt7e3Pv6Iq1ev6p6IZ555Rnx8fBznhw8fLo0bNxY/Pz/Zvn27REdH6zKGyjAoKSkpEhwc7HSvwMBAx7Vy5cq59P5kIAAAKMAmypiYGF1+yH2oc3+Eaqjs3r273q9i3rx5TteioqLkwQcflPr168vgwYPl7bffllmzZt0QxPxRZCAAAChA0dHR+pd6bn8k+2APHo4fPy6bNm1yyj7kpUWLFrqEcezYMalZs6bujUhNTXUaY39+s76JvBBAAABQgCUM73woVxiDhx9++EE2b96s+xzMqAbJIkWKSEBAgH4eEhIir776qr6Xp6enPqeaM1Vw4Wr5QiGAAADATVZhXLp0SQ4fPux4npycrAMA1c9QsWJFeeqpp/QSzrVr18r169d1z4KirqumSNUg+dVXX0loaKheiaGeR0ZGSs+ePR3BwbPPPiuvv/669O/fX/dQ7N+/X2bMmCHTp0+3NFcPm5ts+F3M667CngLgdi5/v7qwpwC4Ja/qTQv0/vdWaJJv9/rh590uj42Pj9e//I369Omj92owNj/aqWyE6ntQwcXQoUPl0KFDuudBje/Vq5cuoeTOgqiNpMLDw2XXrl3i7++v94lQwYQVBBCAGyOAAAongLjHv3G+3evI2T1yJ6KEAQCAm5Qwbics4wQAAJaRgQAAwMBmyynsKbg9AggAAAxyKGGYIoAAAMDATdYXuDV6IAAAgGVkIAAAMKCEYY4AAgAAA0oY5ihhAAAAy8hAAABQgF+mdacigAAAwICdKM1RwgAAAJaRgQAAwIAmSnMEEAAAGLCM0xwlDAAAYBkZCAAADChhmCOAAADAgGWc5gggAAAwIANhjh4IAABgGRkIAAAMWIVhjgACAAADShjmKGEAAADLyEAAAGDAKgxzBBAAABjwZVrmKGEAAADLyEAAAGBACcMcAQQAAAaswjBHCQMAAFhGBgIAAAOaKM0RQAAAYEAJwxwBBAAABgQQ5uiBAAAAlpGBAADAgPyDOQ8beRrkkpmZKTExMRIdHS3e3t6FPR3ALfDnArgRAQScpKeni6+vr6SlpYmPj09hTwdwC/y5AG5EDwQAALCMAAIAAFhGAAEAACwjgIAT1SD22muv0SgG5MKfC+BGNFECAADLyEAAAADLCCAAAIBlBBAAAMAyAggAAGAZAQQc5syZI9WrV5fixYtLixYtZOfOnYU9JaBQbd26VZ544gmpVKmSeHh4yKpVqwp7SoDbIICAtmzZMomKitJL1fbs2SMNGjSQsLAwOXPmTGFPDSg0GRkZ+s+CCq4BOGMZJzSVcWjWrJnMnj1bP8/JyZEqVapIRESEvPzyy4U9PaDQqQzEypUrpUuXLoU9FcAtkIGAZGVlye7du6Vdu3aOc0WKFNHPExISCnVuAAD3RAABOXv2rFy/fl0CAwOdzqvnKSkphTYvAID7IoAAAACWEUBA/P39pWjRopKamup0Xj0PCgoqtHkBANwXAQTEy8tLmjRpIhs3bnScU02U6nlISEihzg0A4J6KFfYE4B7UEs4+ffpI06ZNpXnz5vLOO+/oJWzPP/98YU8NKDSXLl2Sw4cPO54nJydLYmKi+Pn5SdWqVQt1bkBhYxknHNQSzilTpujGyYYNG8rMmTP18k7gryo+Pl5CQ0NvOK+C7YULFxbKnAB3QQABAAAsowcCAABYRgABAAAsI4AAAACWEUAAAADLCCAAAIBlBBAAAMAyAggAAGAZAQQAALCMAAIAAFhGAAEAACwjgAAAAJYRQAAAALHq/wN43ojVrK5zQwAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import seaborn as sns\n",
    "# Testing\n",
    "X_test_embeddings = get_embeddings(df_test[\"text\"].tolist())\n",
    "y_test = df_test[\"label_sexist\"].values\n",
    "\n",
    "y_preds = model.predict(X_test_embeddings)\n",
    "\n",
    "y_preds = (y_preds > 0.5).astype(int)\n",
    "\n",
    "print(classification_report(y_test, y_preds))\n",
    "\n",
    "sns.heatmap(confusion_matrix(y_test, y_preds), annot=True, fmt='d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.6694503]], dtype=float32)"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_text_sexims = \"Oh wow, a woman driving? This should be fun to watch.\"\n",
    "\n",
    "sample_text_sexims = prep_text(sample_text_sexims)\n",
    "sample_text_sexims_embedding = get_embeddings([sample_text_sexims])\n",
    "\n",
    "model.predict(sample_text_sexims_embedding)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spike Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from norse.torch import LIFCell, SequentialState\n",
    "from transformers import BertTokenizer, BertModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ExtendedSpikingTextClassifier(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ExtendedSpikingTextClassifier, self).__init__()\n",
    "        self.model = SequentialState(\n",
    "            # Linear layer input_dim=768 (BERT embedding dim), output_dim=256\n",
    "            nn.Linear(512, 256),\n",
    "            LIFCell(),            # Spiking activation layer\n",
    "            nn.Linear(256, 64),   # Linear layer input_dim=256, output_dim=64\n",
    "            LIFCell(),            # Spiking activation layer\n",
    "            nn.Linear(64, 1),     # Linear layer input_dim=64, output_dim=1\n",
    "            LIFCell(),            # Spiking activation layer\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        output, state = self.model(x)\n",
    "        return output\n",
    "\n",
    "\n",
    "# Instantiate the model, define loss and optimizer\n",
    "model = ExtendedSpikingTextClassifier()\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ğŸš€ Set device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "# Convert training data to PyTorch tensors and move to device\n",
    "X_train_tensor = torch.tensor(X_train_embeddings).float().to(device)\n",
    "y_train_tensor = torch.tensor(y_train).float().to(device)\n",
    "\n",
    "# Create Dataset and DataLoader\n",
    "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "# Training Loop\n",
    "for epoch in range(100):\n",
    "    model.train()  # Set model to training mode\n",
    "    for i, (inputs, labels) in enumerate(train_loader):\n",
    "        inputs, labels = inputs.to(device), labels.to(\n",
    "            device)  # Move to GPU/CPU\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)  # Get raw outputs (logits)\n",
    "        outputs = outputs.squeeze(1)  # Ensure correct shape\n",
    "\n",
    "        # Apply sigmoid for BCELoss\n",
    "        loss = criterion(torch.sigmoid(outputs), labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    if i % 10 == 0:\n",
    "        print(f\"Epoch: {epoch}, Step: {i}, Loss: {loss.item()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6986044329776006\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.66      0.86      0.75      4442\n",
      "         1.0       0.78      0.52      0.62      4085\n",
      "\n",
      "    accuracy                           0.70      8527\n",
      "   macro avg       0.72      0.69      0.69      8527\n",
      "weighted avg       0.72      0.70      0.69      8527\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAhAAAAGdCAYAAABDxkoSAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjEsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvc2/+5QAAAAlwSFlzAAAPYQAAD2EBqD+naQAALtVJREFUeJzt3QucTfX+//H3uA0G4z5DLrnlfgkliThEkRKnknLJrfzpnCg0JddqROVyiDoVKrropAsnEqGiSI3LFB1MIcyQ3AYzxsz/8f367W32clmzmDGbXs/zWI9trfWdNd8557A/8/l8vt8dkpaWliYAAAAPcngZDAAAYBBAAAAAzwggAACAZwQQAADAMwIIAADgGQEEAADwjAACAAB4RgABAAA8I4AAAACe5VKQOLFvW3ZPAQg6+Uo3ze4pAEEpJfn3y+Y9KXfxiroSBU0AAQBA0Eg9md0zCHqUMAAAgGdkIAAAcEpLze4ZBD0CCAAAnFIJINwQQAAA4JBGBsIVPRAAAMAzMhAAADhRwnBFAAEAgBMlDFeUMAAAgGdkIAAAcGIjKVcEEAAAOFHCcEUJAwAAeEYGAgAAJ1ZhuCKAAADAgY2k3FHCAAAAnpGBAADAiRKGKwIIAACcKGG4IoAAAMCJfSBc0QMBAAA8IwMBAIATJQxXBBAAADjRROmKEgYAAPCMDAQAAE6UMFwRQAAA4EQJwxUlDAAA4BkZCAAAHNLS2AfCDQEEAABO9EC4ooQBAAA8IwMBAIATTZSuCCAAAHCihOGKAAIAACc+TMsVPRAAAMAzAggAAM5Wwsisw4Np06apTp06KlSokD0aN26szz77zH+/efPmCgkJCTgefvjhgGds375d7dq1U/78+VWyZEkNHjxYKSkpAWOWLVum+vXrKzQ0VJUrV9bMmTPlFSUMAACCpImyTJkyGjt2rKpUqaK0tDTNmjVLd955p3788UfVrFnTjunTp49Gjx7t/xoTKPicPHnSBg+RkZFauXKldu/erW7duil37tx67rnn7Ji4uDg7xgQes2fP1pIlS9S7d2+VKlVKbdq0yfBcQ9LMDIPAiX3bsnsKQNDJV7ppdk8BCEopyb9n6fOPf/tepj0r7w33XtTXFy1aVOPHj1evXr1sBqJevXqaOHHiWceabMXtt9+uXbt2KSIiwl6bPn26hg4dqr179ypPnjz2zwsWLNDGjRv9X9e5c2cdOHBACxcuzPC8KGEAABAkJYz0TDbh3XffVWJioi1l+JisQfHixVWrVi1FRUXp6NGj/nurVq1S7dq1/cGDYbIKhw4dUmxsrH9Mq1atAr6XGWOue0EJAwCALCxhJCUl2SM903tgjrPZsGGDDRiOHz+uAgUKaN68eapRo4a916VLF5UvX16lS5fW+vXrbTZh8+bN+vDDD+39PXv2BAQPhu/c3DvfGBNkHDt2TPny5cvQz0UAAQBAFoqOjtaoUaMCro0YMUIjR4486/iqVasqJiZGBw8e1AcffKDu3btr+fLlNojo27evf5zJNJi+hZYtW2rr1q2qVKmSLiUCCAAAsjADERUVpUGDBgVcO1f2wTB9CmZlhNGgQQOtWbNGkyZN0iuvvHLG2EaNGtnXLVu22ADCNE+uXr06YEx8fLx9Nfd8r75r6ceYVR8ZzT4Y9EAAAHCWT+PMrCM0NNS/LNN3nC+AcEpNTT2jBOJjMhWGyUQYpvRhSiAJCQn+MYsXL7bf01cGMWPMyov0zJj0fRYZQQYCAIAgERUVpdtuu03lypXT4cOHNWfOHLtnw6JFi2yZwpy3bdtWxYoVsz0QAwcOVLNmzezeEUbr1q1toNC1a1eNGzfO9jsMGzZM/fv39wctZvnmlClTNGTIEPXs2VNLly7V+++/b1dmeEEAAQBAkOwDkZCQYPdtMPs3hIeH28DABA+33HKLduzYoS+++MIu4TQrM8qWLatOnTrZAMEnZ86cmj9/vvr162czCmFhYbaHIv2+ERUqVLDBggk+TGnE7D3x2muvedoDwmAfCCCIsQ8EkD37QBz78rVMe1a+Fr11JSIDAQCAEx/n7YomSgAA4BkZCAAAnC5iB8m/CgIIAACcKGG4ooQBAAA8IwMBAIATJQxXBBAAADhRwnBFCQMAAHhGBgIAACcyEK4IIAAAcKIHwhUlDAAA4BkZCAAAnChhuCKAAADAiRKGKwIIAACcyEC4ogcCAAB4RgYCAAAnShiuCCAAAHCihOGKEgYAAPCMDAQAAE5kIFwRQAAA4JSWlt0zCHqUMAAAgGdkIAAAcKKE4YoAAgAAJwIIV5QwAACAZ2QgAABwYiMpVwQQAAA4UcJwRQABAIATyzhd0QMBAAA8IwMBAIATJQxXBBAAADgRQLiihAEAADwjAwEAgBPLOF0RQAAA4JCWyioMN5QwAACAZ2QgAABwoonSFQEEAABO9EC4ooQBAAA8IwMBAIATTZSuCCAAAHCiB8IVAQQAAE4EEK7ogQAAAJ6RgQAAwImP83ZFBuIK8+68+bqrWz81uqWjPe7vO1BfrVrjv7/vj/16YvR43dy+i65r2UF3PzhAi7/8OuAZA4aMVKuO3VS/xR1qfkcXOz5h7x8BYzZviVO3fo/bMS3v6qo3Zs+9ZD8jkFlKl47UrJmTFb97ow4f3KIff/hCDerX8d/v0OE2fbZgjr2fkvy76tatGfD1RYoU1sQJYxS7cYX9+m1bVmvCS6NVqFDBbPhpkOkljMw6rlBkIK4wkSWKa+DDD6p82auUlpamjz/7Qo88MVofzJiiyhXLK2rMCzp8JFFTnh+hwuGF9N/Fy/TY8Gi99/okVb+msn3G9fXrqk+3e1WieFHF7/1DL0x5TQOHPavZr7xk7x9JTFTfgU/phob1NHzwI/plW5yGPzdRBQuE6e4722bzfwNAxhQuHK4Vyz7SsuUrdXv7B7R33x+qUrmC/jxw0D8mLCy/vlm5WnM/+FSvvvLCGc8oXTrCHkOHjtFPP/+i8uXKaOrUsTYwubdz30v8EwGXFgHEFab5TTcEnP/zoR56b94CrYvdZAOImI0/6+nHB6h2jar2/kM97tOb781T7KYt/gCiW+e7/F9fOjJCvR+4R/+IGq0TKSnKnSuX5n/+pU6cOKFnnhyo3Llz2+du/t82vfnuPAIIXDaGDP5/2rlzl3r3GeS/9uuvOwLGzJ79H/tavnyZsz4jNnaz7rn3dKCwbdtvenr483pz5mTlzJlTJ0+ezLL5I4uxjNMVJYwrmPnH679fLNOx48dVr1Y1e61erepauGSFDh46rNTUVHs/OTlZ16dL26ZnxpmAoV7t6jZ4MNZt3KSG9Wrb4MGnyfUNFLd9px0PXA5uv7211q5dr3ffeUW7dq7TmtWL1Ktnl4t+bnihgjp06AjBw5WwE2VmHVcozxmIffv26Y033tCqVau0Z88eey0yMlI33nijevTooRIlSmTFPOHBL1vjdP9Dg2xgkD9fPk167mlVqlDe3ntxzJN6fHi0mtx2j3LlzKm8eUM18bmnVa5M6YBnvPTy63rnP5/q2PEk1a1ZTVPHjwrooyhTOjJgfLGihU/d2/+n/QcUCHYVK5TTQw911cRJ/9bY5yerYYN6mjhhtJJPnNBbb11YT0+xYkX01JOP6rXXZ2f6fIHLOgOxZs0aXXPNNZo8ebLCw8PVrFkze5g/m2vVqlXT999/7/qcpKQkHTp0KOAw15A5KpQro//MnKo5r07UPR3a6alnX9TWuN/svSn/ftP2QLw26Tm9+/pkdevc0QYUJuhI78Euf9fcGVP06oRnlSNnDts7YXoqgCtFjhw59OOPGzXs6bGKiYm1b/qvvT5HD/XpekHPK1iwgD79+E39/PMvGjX6xUyfL7KhhJFZhwfTpk1TnTp1VKhQIXs0btxYn332mf/+8ePH1b9/fxUrVkwFChRQp06dFB8fH/CM7du3q127dsqfP79KliypwYMHKyUlJWDMsmXLVL9+fYWGhqpy5cqaOXOmsjQD8cgjj+juu+/W9OnTFRISEnDPvLk8/PDDdozJTpxPdHS0Ro06/RutMWzwPzR8yD+9TAfnYEoLvoxCzWpVFLvpF70992MbFMz5z6f66K3ptm/BqFalon5Yt1Hv/Ge+Rgx5xP+MIoXD7XF1uTKqeHVZtbqrm+2jMCWQ4sWK6o/9BwK+p++8eNEil/RnBS7U7t0JtvExvU2btqjjXd77eAoUCNN/58/W4cOJ6nR37zP+scblJy2bVk+UKVNGY8eOVZUqVez76qxZs3TnnXfqxx9/VM2aNTVw4EAtWLBAc+fOtb+8DxgwQB07dtQ333xjv96UzkzwYCoDK1eu1O7du9WtWzf7vvDcc8/ZMXFxcXaMec+ePXu2lixZot69e6tUqVJq06ZN1gQQ69ats1GKM3gwzDXzg1177bWuz4mKitKgQacbl4wch3/3MhV4kJqapuTkEzr+f1mekBwhZ/wmlnaeOl3a/0XQ5hlG3VrVNPmVWf6mSmPlmh9t5oPyBS4XK1etUdVrKgVcu6ZKRW3f/rvnzINZ6mmyqB069iCbiovSvn37gPNnn33WZiW+/fZbG1y8/vrrmjNnjv72t7/Z+zNmzFD16tXt/RtuuEGff/65fvrpJ33xxReKiIhQvXr1NGbMGA0dOlQjR45Unjx5bBKgQoUKevHFU5ky8/Vff/21JkyY4CmA8FTCMBHN6tWrz3nf3DMTdmNSJr70jO8w13DxJkyboe9jNuj33fG2LGHO1/y4Xu1at1CF8mVtZmL0uH9pw0+btX3nLs185z9ateZH/a1pY/v162M3ac4Hn2jTL1u1a0+8vlsbo8Ejn1fZq0r5GzHb3dLCRrPDoydqy7bf9NkXyzV77kcBqzeAYDdp0r/VqFF9PTH0EVWqdLU6d+6g3r3v18vTZwbs82D2fqhR/Rp7fs01lex5REQJf/Cw8L/vKH9YPvV56HG7/4O5Zw4TmOMylokljKQLLNubbMK7776rxMREW8pYu3atXQHXqlUr/xjTOlCuXDl/5t+81q5dO+C92AQF5nvGxsb6x6R/hm+MW/XgojIQjz/+uPr27Wt/iJYtW/onaOovJgXy73//Wy+8cOZaaVw6+w8c0JNjXtDeP/arYFiYrqlcQa+89IxuvL6+vT/thdE2qOg/ZKSOHTumsmVK69lhj6nZjdfb+6ap8ovlKzX19bft6o0SxYqqSaMGemhMlI1cDbPfg+mNePbFqbqn1yMqEl5IDz/YhSWcuKx8v3ad/n53bz3zzBMa9tSjivt1hwY9NkLvvDPPP6b97a31xusT/OfvzJ5mX0ePeVGjx7yk+tfWtkGI8cumlQHPr1SlkX77becl+3mQyTJx9UT0Wcr2I0aMsBmBs9mwYYMNGEy/g+lzmDdvnmrUqKGYmBj773Dhwqea1n3Me7FvUYN5df4i7zt3G2OCDPO+kC9fvswPIEzjRvHixW2a4+WXX/YvUzLrnRs0aGDLG/fcc4+XRyKTjYkaeN77ZoOpic8NO+f9aypV0Bv/Guv6fapWrqA3pxEs4vK24L9f2ONc3nzrfXucy/IVq5Qrz1VZNDtcKftARJ2lbH++rHvVqlVtsHDw4EF98MEH6t69u5YvX67Lfhnnvffeaw+TRjFLOg0TVKTfEwAAAJwOFryU6U2WwayMMMwv52YF5KRJk+x7r1mef+DAgYAshKkCmBaDc7Ua+FZppB/jXLlhzk07QUazD8YFF+lMwGA6Ns1B8AAAuKIE0WdhpKam2p4JE0yY91vTMuCzefNmu2zTlDwM82pKIAkJCf4xixcvtsGBKYP4xqR/hm+M7xkZxVbWAAAEyVbWUVFRuu2222xj5OHDh+2KC7Nnw6JFi+yyzV69etlySNGiRW1QYLZOMG/8ZgWG0bp1axsodO3aVePGjbP9DsOGDbMtCL4siFm+OWXKFA0ZMkQ9e/bU0qVL9f7779vloV4QQAAAECQSEhLsvg1m/wYTMJhNpUzwcMstt9j7pgfRrPAxG0iZrIRZPWF6En1MT+L8+fPVr18/G1iEhYXZHorRo0f7x5glnCZYMFsvmNKIWR762muveVrCaYSkBcn2gif2bcvuKQBBJ1/pptk9BSAomY9Xz0qJT2fegoCwMeduxL2ckYEAAMCJT+N0xU4nAADAMzIQAAAEyWdhXE4IIAAAcKKE4YoSBgAA8IwMBAAATmQgXBFAAACQhR+mdaUigAAAwIkMhCt6IAAAgGdkIAAAcEgjA+GKAAIAACcCCFeUMAAAgGdkIAAAcGInSlcEEAAAOFHCcEUJAwAAeEYGAgAAJzIQrgggAABwSEsjgHBDCQMAAHhGBgIAACdKGK4IIAAAcCKAcEUAAQCAA1tZu6MHAgAAeEYGAgAAJzIQrgggAABwYidrV5QwAACAZ2QgAABwoInSHQEEAABOBBCuKGEAAADPyEAAAOBEE6UrAggAABzogXBHCQMAAHhGBgIAACdKGK4IIAAAcKCE4Y4AAgAAJzIQruiBAAAAnpGBAADAIY0MhCsCCAAAnAggXFHCAAAAnpGBAADAgRKGOwIIAACcCCBcUcIAAACekYEAAMCBEoY7AggAABwIINwRQAAA4EAA4Y4eCAAA4BkZCAAAnNJCsnsGQY8MBAAAZylhZNbhRXR0tK677joVLFhQJUuWVIcOHbR58+aAMc2bN1dISEjA8fDDDweM2b59u9q1a6f8+fPb5wwePFgpKSkBY5YtW6b69esrNDRUlStX1syZMz3NlQACAIAgsXz5cvXv31/ffvutFi9erBMnTqh169ZKTEwMGNenTx/t3r3bf4wbN85/7+TJkzZ4SE5O1sqVKzVr1iwbHAwfPtw/Ji4uzo5p0aKFYmJi9Oijj6p3795atGhRhucakpaWFhQfen5i37bsngIQdPKVbprdUwCCUkry71n6/N03tci0Z5X6+ssL/tq9e/faDIIJLJo1a+bPQNSrV08TJ04869d89tlnuv3227Vr1y5FRETYa9OnT9fQoUPt8/LkyWP/vGDBAm3cuNH/dZ07d9aBAwe0cOHCDM2NDAQAAFlYwkhKStKhQ4cCDnMtIw4ePGhfixYtGnB99uzZKl68uGrVqqWoqCgdPXrUf2/VqlWqXbu2P3gw2rRpY79vbGysf0yrVq0CnmnGmOsZRQABAEAWio6OVnh4eMBhrrlJTU21pYUmTZrYQMGnS5cuevvtt/Xll1/a4OGtt97SAw884L+/Z8+egODB8J2be+cbY4KMY8eOZejnYhUGAAAOaZm4CiMqKkqDBg0KuGYaF92YXghTYvj6668Drvft29f/Z5NpKFWqlFq2bKmtW7eqUqVKulQIIAAAyMKNpEJDQzMUMKQ3YMAAzZ8/XytWrFCZMmXOO7ZRo0b2dcuWLTaAiIyM1OrVqwPGxMfH21dzz/fqu5Z+TKFChZQvX74MzZESBgAAQSItLc0GD/PmzdPSpUtVoUIF168xqygMk4kwGjdurA0bNighIcE/xqzoMMFBjRo1/GOWLFkS8BwzxlzPKDIQAAA4pKVmz0ZS/fv315w5c/Txxx/bvSB8PQumb8JkBkyZwtxv27atihUrpvXr12vgwIF2hUadOnXsWLPs0wQKXbt2tcs7zTOGDRtmn+3LhJh9I6ZMmaIhQ4aoZ8+eNlh5//337cqMjGIZJxDEWMYJZM8yzu0NW2bas8p9H/ib/vmYTaHOZsaMGerRo4d27NhhGyZNb4TZG6Js2bK66667bIBgMgw+v/32m/r162c3iwoLC1P37t01duxY5cp1Om9g7png46effrJlkqefftp+jwzPlQACCF4EEED2BBC/1Q9c4ngxyv/wha5E9EAAAADP6IEAACBIeiAuJwQQAAA4BEdxP7hRwgAAAJ6RgQAAwIEShjsCCAAAsnAr6ysVJQwAAOAZGQgAALLwszCuVAQQAAA4pFLCcEUJAwAAeEYGAgAAB5oo3RFAAADgwDJOdwQQAAA4sBOlO3ogAACAZ2QgAABwoIThjgACAAAHlnG6o4QBAAA8IwMBAIADyzjdEUAAAODAKgx3lDAAAIBnZCAAAHCgidIdAQQAAA70QLijhAEAADwjAwEAgANNlO4IIAAAcKAH4jIKID6q/XR2TwEIOl8UuTG7pwD8JdED4Y4eCAAAcPlmIAAACBaUMNwRQAAA4EAPpTtKGAAAwDMyEAAAOFDCcEcAAQCAA6sw3FHCAAAAnpGBAADAITW7J3AZIIAAAMAhTZQw3FDCAAAAnpGBAADAIZWNIFwRQAAA4JBKCcMVAQQAAA70QLijBwIAAHhGBgIAAAeWcbojgAAAwIEShjtKGAAAwDMyEAAAOFDCcEcAAQCAAwGEO0oYAADAMzIQAAA40ETpjgwEAAAOqSGZd3gRHR2t6667TgULFlTJkiXVoUMHbd68OWDM8ePH1b9/fxUrVkwFChRQp06dFB8fHzBm+/btateunfLnz2+fM3jwYKWkpASMWbZsmerXr6/Q0FBVrlxZM2fO9DRXAggAAILE8uXLbXDw7bffavHixTpx4oRat26txMRE/5iBAwfq008/1dy5c+34Xbt2qWPHjv77J0+etMFDcnKyVq5cqVmzZtngYPjw4f4xcXFxdkyLFi0UExOjRx99VL1799aiRYsyPNeQtLS0oPjIkLml7s/uKQBBp0RqcnZPAQhKzePnZunzP47skmnPunPPnAv+2r1799oMggkUmjVrpoMHD6pEiRKaM2eO/v73v9sxmzZtUvXq1bVq1SrdcMMN+uyzz3T77bfbwCIiIsKOmT59uoYOHWqflydPHvvnBQsWaOPGjf7v1blzZx04cEALFy7M0NzIQAAA4JCWiUdSUpIOHToUcJhrGWECBqNo0aL2de3atTYr0apVK/+YatWqqVy5cjaAMMxr7dq1/cGD0aZNG/t9Y2Nj/WPSP8M3xveMjCCAAADgLMs4M+uIjo5WeHh4wGGuuc4hNdWWFpo0aaJatWrZa3v27LEZhMKFCweMNcGCuecbkz548N333TvfGBNkHDt2LEP/HbEKAwCALBQVFaVBgwYFXDONi25ML4QpMXz99dcKRgQQAAA4pIZk3jLO0NDQDAUM6Q0YMEDz58/XihUrVKZMGf/1yMhI2xxpehXSZyHMKgxzzzdm9erVAc/zrdJIP8a5csOcFypUSPny5cvQHClhAACQhT0QXph1DSZ4mDdvnpYuXaoKFSoE3G/QoIFy586tJUuW+K+ZZZ5m2Wbjxo3tuXndsGGDEhIS/GPMig4THNSoUcM/Jv0zfGN8z8gIMhAAAASJ/v372xUWH3/8sd0LwtezYPomTGbAvPbq1cuWRExjpQkKHnnkEfvGb1ZgGGbZpwkUunbtqnHjxtlnDBs2zD7blwl5+OGHNWXKFA0ZMkQ9e/a0wcr7779vV2ZkFAEEAABB8lkY06ZNs6/NmzcPuD5jxgz16NHD/nnChAnKkSOH3UDKrOYwqydefvll/9icOXPa8ke/fv1sYBEWFqbu3btr9OjR/jEms2GCBbOnxKRJk2yZ5LXXXrPPyij2gQCCGPtAANmzD8Q7pTPvPem+XbN1JaIHAgAAeEYJAwAAh1Q+TMsVAQQAAA5BUdsPcpQwAACAZ2QgAABw8Pox3H9FBBAAAATJMs7LCQEEAAAO9EC4owcCAAB4RgYCAAAHeiDcEUAAAOBAD4Q7ShgAAMAzMhAAADiQgXBHAAEAgEMaPRCuKGEAAADPyEAAAOBACcMdAQQAAA4EEO4oYQAAAM/IQAAA4MBW1u4IIAAAcGAnSncEEAAAONAD4Y4eCAAA4BkZCAAAHMhAuCOAAADAgSZKd5QwAACAZ2QgAABwYBWGOwIIAAAc6IFwRwkDAAB4RgYCAAAHmijdEUAAAOCQSgjhihIGAADwjAwEAAAONFG6I4AAAMCBAoY7AggAABzIQLijBwIAAHhGBgIAAAd2onRHAAEAgAPLON1RwgAAAJ6RgQAAwIH8gzsCCAAAHFiF4Y4SBgAA8IwMBAAADjRRuiOAAADAgfDBHSUMAADgGRkIAAAcaKJ0RwABAIADPRDuCCAAAHAgfHBHDwQAAEFixYoVat++vUqXLq2QkBB99NFHAfd79Ohhr6c/br311oAx+/fv1/33369ChQqpcOHC6tWrl44cORIwZv369WratKny5s2rsmXLaty4cZ7nSgABAMBZeiAy6/AiMTFRdevW1dSpU885xgQMu3fv9h/vvPNOwH0TPMTGxmrx4sWaP3++DUr69u3rv3/o0CG1bt1a5cuX19q1azV+/HiNHDlSr776qqe5UsIAAMAhLZuKGLfddps9zic0NFSRkZFnvffzzz9r4cKFWrNmjRo2bGiv/etf/1Lbtm31wgsv2MzG7NmzlZycrDfeeEN58uRRzZo1FRMTo5deeikg0HBDBgIAgCyUlJRkf+tPf5hrF2rZsmUqWbKkqlatqn79+umPP/7w31u1apUtW/iCB6NVq1bKkSOHvvvuO/+YZs2a2eDBp02bNtq8ebP+/PPPDM+DAAIAgCwsYURHRys8PDzgMNcuhClfvPnmm1qyZImef/55LV++3GYsTp48ae/v2bPHBhfp5cqVS0WLFrX3fGMiIiICxvjOfWMyghIGAABZuIwzKipKgwYNOqMMcSE6d+7s/3Pt2rVVp04dVapUyWYlWrZsqUuJDAQAAFkoNDTUrohIf1xoAOFUsWJFFS9eXFu2bLHnpjciISEhYExKSopdmeHrmzCv8fHxAWN85+fqrTgbAggAABzSMvHISjt37rQ9EKVKlbLnjRs31oEDB+zqCp+lS5cqNTVVjRo18o8xKzNOnDjhH2NWbJieiiJFimT4e1PCuAIVv6GaqvZrpyJ1KihfZBF98+BL2rXw9P+ZQosXUp1h9yni5trKHZ5f+77dpB+fmqUjcacj0pv/85RK3lgj4Llb31yiH4a+4T8vUreiaj91r/0+5m/J/pitWj/mHR38afsl+kmBjCv3jw4q3raR8le5SqnHk3VozWZtHTNbx7bu8o8p1bWVIu66SQXqVFCugvn1dZXuSjl01H8/b9kSKj/o7yp8Uy3lKVFYyfH7Ff/BV/pt4odKO5Fix1z9+N26evA9Z3z/k0eP66sKXS/RT4vLdSfKI0eO+LMJRlxcnF0hYXoYzDFq1Ch16tTJZgq2bt2qIUOGqHLlyrYJ0qhevbrtk+jTp4+mT59ug4QBAwbY0odZgWF06dLFPsfsDzF06FBt3LhRkyZN0oQJEzzNlQDiCpQrf6gO/LRdce8uV5M3Bp5xv8mMQUpNOalverykE0eO6ZqHblOz95/UomZDdPLY6c7gbW8v1cZxH/jPTx5L9v85Z/5QNZ0zRLs+/0E/RM1Ujpw5VHPw39XsnaGa3+AfSks51dADBIvCjWtq14xFOhSzRSE5c6rik11U971hWt1soFKPnvr/fc58ebT/yxh7VBx2/xnPyF/5KikkRL88/oqO/bpHYdXKqeqLD9m/D1tHvWXH7Hj5U+2atTjg6+p+MFyHY7Zeop8Ul7Pvv/9eLVq08J/7eie6d++uadOm2Q2gZs2aZbMMJiAw+zmMGTMmoCRilmmaoMH0RJjVFybgmDx5sv++aeL8/PPP1b9/fzVo0MCWQIYPH+5pCadBAHEF2rN0nT3OpkDFSBVrWEWLbh6iQ7/8bq/9MHSG2q+fqnJ3NVbcnGX+sSnHkpS09+BZn1OoSmmFFi2o2PEf6Niu/fZa7Isfqs2XY5W/THEl/hpYXwOy2/r7ng043/TPqWry0+sqWKeiDn77s72289X/2tfCjuybjy+48Dn+W4J2VCqt0j1a+wMIk2kwh09YjfIKq1ZWvwzxtkkP/pofptW8eXOlpZ07+7Fo0SLXZ5hMxZw5c847xjRffvXVV7oY9ED8xeTIk9u+nkw6XftSWppSk1JU/PqqAWPLd2yiO2Knq/WXY1XryXvtb2c+h7fsVtL+w6pwX3OF5M6pHHlzq0KXm21QcnTH3kv3AwEXyJQojJQDRy7uOYXyK+XPcz+j1AMtdXTLLh38btNFfR9c+o2kMus/VyoyEH8xh7fsUuLOfar95L1aO+R1pRxN0jV9b1P+q4opb0Rh/7jt81bq6M59OrbngArXKKvaT92ngpVKaVWvifZ+SuJxLev4jJrMGKgaA+869ey4PfrqvueVdpIPwkWQCwlR5Wd62Df1xE07Lvgx+a6O1FW9btPWUW+e9X6O0NyK6NhU2/817yImi+zAv2LZkIHYsWOHevbs6XlXrhNp1MwvBdObsLLXBBWsWEodNv1bHbfNUMkmNbR7SYzSUk9HynFvf6n4ZRt0aNMObf9wpVb/Y5rKtL1OYeVPbVBiMg4NX+qjfWt+0ZJ2I7T0jlE6tGmnbnrrcXsPCGZVxvZWWNWy+ukhb01j6eWJLKo67z6lvZ+u0u63l5x1TPG21ytngbza8/7yi5gt8BcJIMxaU9PgcT5n25Vr3pHYzJ4KzuHA+l+1+JYnNe+a3vq0Xn991WWc8hQpoMTfAtcOp7f/h1MNYAUqnNqtrNxdNyqsbAmtefRV/blum/b/sEXf/r8pCitXQle1aXDJfhbAqyrP9VKxW+orptMoJe0+1b/jVZ6IIqr34QgdXLNZmx975ZzjSt3fUn8s/kEnztFLhOBFCSMLShiffPLJee9v27btgnblmn+Nt+5PXLyUw8f8QUHRuhUVm27FhVPhWuXt6/H4A/Y1V75QpaWm2v4JP5PBMKc5aK1B8AYPJisQc9cIHd9+7oDZLfNggofD67dp0z9fDvw7kE7eciVVuElNbez2/EXOGtmBEkYWBBAdOnSwnz9+vi5Rc/98zHIT5y5cuUNyep0KzsEsKStQ4fRuYiYrEF6zvJIPHNGx3/9QmduvV9Ifh3X0930Kr15O9cZ01e8Lv1f88g2nxpcvqXIdb7RljeT9RxReo5zqjXpAe1f9rIM/n6oXx6/YoDpP36dro3toyxuf2//Nqz1yh10euvebn7LtZwfOV7aI6HiTNnQfp5NHjtt9HIyUw0ftvhCGuZanZGHl+7+/P2HVy9mxx3/fZ5stbfAwb6SSdu7V1pFvKU+xQv7nJ+89FVz7RN7XQsnxB/THktOrNoC/dABhdrt6+eWXdeedd571vtnwwqwrRfYx2YTmHw7zn9cbdWrzml/fW6E1j76ivBFFVHfkA8pbIlzHEg7ot7lf6acJp5u8Uk+kKKJpLVXpfavdU+Lorv3auWCNfp74UcAqjK+7v6iaj3XU3z4dabMPf2781ZZDjicE/kMKBIOrHjy10c61H40KuL7pH1O1571Ty5dLd78lYBOoaz8ZEzCm6M11lL9iKXvcuC6wdLEs4u7TJyEhiry3+annmkwdLjup5/klGaeEpJ0vlXAWd9xxh+rVq6fRo0ef9f66det07bXX2m0zvZhb6sxNW4C/uhKppzfvAnBa8/i5Wfr8B8p3zLRnvf3bh7oSec5ADB48WImJiee8b7bU/PLLLy92XgAA4EoKIJo2bXre+2FhYbr55psvZk4AAPwlPwvjcsJGUgAAOFzJyy8zC+vtAACAZ2QgAABwYO2MOwIIAAAc6IFwRwABAIADPRDu6IEAAACekYEAAMCBHgh3BBAAADh43KT5L4kSBgAA8IwMBAAADqzCcEcAAQCAAz0Q7ihhAAAAz8hAAADgwD4Q7gggAABwoAfCHSUMAADgGRkIAAAc2AfCHQEEAAAOrMJwRwABAIADTZTu6IEAAACekYEAAMCBVRjuCCAAAHCgidIdJQwAAOAZGQgAABwoYbgjgAAAwIFVGO4oYQAAAM/IQAAA4JBKE6UrAggAABwIH9xRwgAAAJ6RgQAAwIFVGO4IIAAAcCCAcEcAAQCAAztRuqMHAgAAeEYGAgAAB0oY7gggAABwYCdKd5QwAACAZ2QgAABwoInSHQEEAAAO9EC4o4QBAECQWLFihdq3b6/SpUsrJCREH3300RmZkeHDh6tUqVLKly+fWrVqpf/9738BY/bv36/7779fhQoVUuHChdWrVy8dOXIkYMz69evVtGlT5c2bV2XLltW4ceM8z5UAAgAAB/NGnVmHF4mJiapbt66mTp161vvmjX7y5MmaPn26vvvuO4WFhalNmzY6fvy4f4wJHmJjY7V48WLNnz/fBiV9+/b13z906JBat26t8uXLa+3atRo/frxGjhypV1991dNcQ9KCpNAzt9T92T0FIOiUSE3O7ikAQal5/NwsfX7dyBsz7Vnr9qy8oK8zGYh58+apQ4cO9ty8XZvMxGOPPabHH3/cXjt48KAiIiI0c+ZMde7cWT///LNq1KihNWvWqGHDhnbMwoUL1bZtW+3cudN+/bRp0/TUU09pz549ypMnjx3zxBNP2GzHpk2bMjw/MhAAAGShpKQk+1t/+sNc8youLs6+6ZuyhU94eLgaNWqkVatW2XPzasoWvuDBMONz5MhhMxa+Mc2aNfMHD4bJYmzevFl//vlnhudDAAEAwFn2gcis/0RHR9s3+vSHueaVCR4Mk3FIz5z77pnXkiVLBtzPlSuXihYtGjDmbM9I/z0yglUYAAA4pGZidT8qKkqDBg0KuBYaGqrLHQEEAABZuBNlaGhopgQMkZGR9jU+Pt6uwvAx5/Xq1fOPSUhICPi6lJQUuzLD9/Xm1XxNer5z35iMoIQBAMBloEKFCvYNfsmSJf5rpp/C9DY0btzYnpvXAwcO2NUVPkuXLlVqaqrtlfCNMSszTpw44R9jVmxUrVpVRYoUyfB8CCAAADhLCSOzDi/Mfg0xMTH28DVOmj9v377drsp49NFH9cwzz+iTTz7Rhg0b1K1bN7uywrdSo3r16rr11lvVp08frV69Wt98840GDBhgV2iYcUaXLl1sA6XZH8Is93zvvfc0adKkM8osbihhAAAQJB+m9f3336tFixb+c9+bevfu3e1SzSFDhti9Isy+DibTcNNNN9llmmZDKJ/Zs2fboKFly5Z29UWnTp3s3hE+ponz888/V//+/dWgQQMVL17cbk6Vfq+IjGAfCCCIsQ8EkD37QFQreV2mPWtTwhpdichAAACQhaswrlQEEAAABEkJ43JCEyUAAPCMDAQAAA6UMNwRQAAA4EAJwx0lDAAA4BkZCAAAHNLSUrN7CkGPAAIAAIdUShiuCCAAAHAIkj0Wgxo9EAAAwDMyEAAAOFDCcEcAAQCAAyUMd5QwAACAZ2QgAABwYCdKdwQQAAA4sBOlO0oYAADAMzIQAAA40ETpjgACAAAHlnG6o4QBAAA8IwMBAIADJQx3BBAAADiwjNMdAQQAAA5kINzRAwEAADwjAwEAgAOrMNwRQAAA4EAJwx0lDAAA4BkZCAAAHFiF4Y4AAgAABz5Myx0lDAAA4BkZCAAAHChhuCOAAADAgVUY7ihhAAAAz8hAAADgQBOlOwIIAAAcKGG4I4AAAMCBAMIdPRAAAMAzMhAAADiQf3AXkkaeBukkJSUpOjpaUVFRCg0Nze7pAEGBvxfAmQggEODQoUMKDw/XwYMHVahQoeyeDhAU+HsBnIkeCAAA4BkBBAAA8IwAAgAAeEYAgQCmQWzEiBE0igHp8PcCOBNNlAAAwDMyEAAAwDMCCAAA4BkBBAAA8IwAAgAAeEYAAb+pU6fq6quvVt68edWoUSOtXr06u6cEZKsVK1aoffv2Kl26tEJCQvTRRx9l95SAoEEAAeu9997ToEGD7FK1H374QXXr1lWbNm2UkJCQ3VMDsk1iYqL9u2CCawCBWMYJy2QcrrvuOk2ZMsWep6amqmzZsnrkkUf0xBNPZPf0gGxnMhDz5s1Thw4dsnsqQFAgAwElJydr7dq1atWqlf9ajhw57PmqVauydW4AgOBEAAHt27dPJ0+eVERERMB1c75nz55smxcAIHgRQAAAAM8IIKDixYsrZ86cio+PD7huziMjI7NtXgCA4EUAAeXJk0cNGjTQkiVL/NdME6U5b9y4cbbODQAQnHJl9wQQHMwSzu7du6thw4a6/vrrNXHiRLuE7cEHH8zuqQHZ5siRI9qyZYv/PC4uTjExMSpatKjKlSuXrXMDshvLOOFnlnCOHz/eNk7Wq1dPkydPtss7gb+qZcuWqUWLFmdcN8H2zJkzs2VOQLAggAAAAJ7RAwEAADwjgAAAAJ4RQAAAAM8IIAAAgGcEEAAAwDMCCAAA4BkBBAAA8IwAAgAAeEYAAQAAPCOAAAAAnhFAAAAAzwggAACAvPr/+ttoV/RilJYAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# accuracy on test data\n",
    "\n",
    "X_test_tensor = torch.tensor(X_test_embeddings).float().to(device)\n",
    "y_test_tensor = torch.tensor(y_test).float().to(device)\n",
    "\n",
    "model.eval()  # Set model to evaluation mode\n",
    "with torch.no_grad():\n",
    "    outputs = model(X_test_tensor)\n",
    "    outputs = outputs.squeeze(1)  # Ensure correct shape\n",
    "    predictions = torch.sigmoid(outputs) > 0.5\n",
    "    accuracy = (predictions == y_test_tensor).sum().item() / len(y_test_tensor)\n",
    "    print(f\"Accuracy: {accuracy}\")\n",
    "    print(classification_report(y_test_tensor.cpu(), predictions.cpu()))\n",
    "    sns.heatmap(confusion_matrix(y_test_tensor.cpu(), predictions.cpu()), annot=True, fmt='d')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BERT LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model directly\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "    \"NLP-LTU/bertweet-large-sexism-detector\")\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    \"NLP-LTU/bertweet-large-sexism-detector\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_final.sample(frac=1, random_state=42).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df[df[\"split\"] == \"train\"]\n",
    "df_val = df[df[\"split\"] == \"dev\"]\n",
    "df_test = df[df[\"split\"] == \"test\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n"
     ]
    }
   ],
   "source": [
    "# Use a pipeline as a high-level helper\n",
    "from transformers import pipeline\n",
    "\n",
    "pipe = pipeline(\"text-classification\", model=\"NLP-LTU/bertweet-large-sexism-detector\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\prans\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\transformers\\training_args.py:1594: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ğŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# training arguments\n",
    "\n",
    "from transformers import TrainingArguments\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    per_device_train_batch_size=32,\n",
    "    num_train_epochs=3,\n",
    "    logging_dir='./logs',\n",
    "    logging_steps=10,\n",
    "    evaluation_strategy=\"steps\",\n",
    "    eval_steps=10,\n",
    "    save_steps=10,\n",
    "    save_total_limit=1,\n",
    "    load_best_model_at_end=True\n",
    ")\n",
    "\n",
    "# Prepare the dataset\n",
    "from datasets import Dataset\n",
    "\n",
    "train_dataset = Dataset.from_pandas(df_train)\n",
    "val_dataset = Dataset.from_pandas(df_val)\n",
    "test_dataset = Dataset.from_pandas(df_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29574/29574 [00:04<00:00, 6094.15 examples/s]\n",
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4229/4229 [00:00<00:00, 7469.26 examples/s]\n",
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8527/8527 [00:01<00:00, 7210.91 examples/s]\n"
     ]
    }
   ],
   "source": [
    "max_length = 128  # Ensure consistent sequence length\n",
    "\n",
    "train_dataset = train_dataset.map(lambda x: tokenizer(\n",
    "    x[\"text\"], truncation=True, padding='max_length', max_length=max_length), batched=True)\n",
    "\n",
    "val_dataset = val_dataset.map(lambda x: tokenizer(\n",
    "    x[\"text\"], truncation=True, padding='max_length', max_length=max_length), batched=True)\n",
    "\n",
    "test_dataset = test_dataset.map(lambda x: tokenizer(\n",
    "    x[\"text\"], truncation=True, padding='max_length', max_length=max_length), batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset.set_format(type='torch', columns=['input_ids', 'attention_mask', 'label_sexist'])\n",
    "val_dataset.set_format(type='torch', columns=['input_ids', 'attention_mask', 'label_sexist'])\n",
    "test_dataset.set_format(type='torch', columns=['input_ids', 'attention_mask', 'label_sexist'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train\n",
    "from transformers import Trainer\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=val_dataset\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pipe' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mpipe\u001b[49m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWomen needs to be in kitchen\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'pipe' is not defined"
     ]
    }
   ],
   "source": [
    "pipe(\"Women needs to be in kitchen\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[32], line 21\u001b[0m\n\u001b[0;32m     17\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mfunctional\u001b[38;5;241m.\u001b[39msoftmax(outputs\u001b[38;5;241m.\u001b[39mlogits, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mnumpy()\n\u001b[0;32m     20\u001b[0m \u001b[38;5;66;03m# Explain a sexist tweet\u001b[39;00m\n\u001b[1;32m---> 21\u001b[0m exp \u001b[38;5;241m=\u001b[39m \u001b[43mexplainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexplain_instance\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlime_predict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_features\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     22\u001b[0m exp\u001b[38;5;241m.\u001b[39mshow_in_notebook()\n",
      "File \u001b[1;32mc:\\Users\\prans\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\lime\\lime_text.py:413\u001b[0m, in \u001b[0;36mLimeTextExplainer.explain_instance\u001b[1;34m(self, text_instance, classifier_fn, labels, top_labels, num_features, num_samples, distance_metric, model_regressor)\u001b[0m\n\u001b[0;32m    406\u001b[0m indexed_string \u001b[38;5;241m=\u001b[39m (IndexedCharacters(\n\u001b[0;32m    407\u001b[0m     text_instance, bow\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbow, mask_string\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmask_string)\n\u001b[0;32m    408\u001b[0m                   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchar_level \u001b[38;5;28;01melse\u001b[39;00m\n\u001b[0;32m    409\u001b[0m                   IndexedString(text_instance, bow\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbow,\n\u001b[0;32m    410\u001b[0m                                 split_expression\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msplit_expression,\n\u001b[0;32m    411\u001b[0m                                 mask_string\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmask_string))\n\u001b[0;32m    412\u001b[0m domain_mapper \u001b[38;5;241m=\u001b[39m TextDomainMapper(indexed_string)\n\u001b[1;32m--> 413\u001b[0m data, yss, distances \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__data_labels_distances\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    414\u001b[0m \u001b[43m    \u001b[49m\u001b[43mindexed_string\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclassifier_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_samples\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    415\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdistance_metric\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdistance_metric\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    416\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclass_names \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    417\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclass_names \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mstr\u001b[39m(x) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(yss[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m])]\n",
      "File \u001b[1;32mc:\\Users\\prans\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\lime\\lime_text.py:482\u001b[0m, in \u001b[0;36mLimeTextExplainer.__data_labels_distances\u001b[1;34m(self, indexed_string, classifier_fn, num_samples, distance_metric)\u001b[0m\n\u001b[0;32m    480\u001b[0m     data[i, inactive] \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m    481\u001b[0m     inverse_data\u001b[38;5;241m.\u001b[39mappend(indexed_string\u001b[38;5;241m.\u001b[39minverse_removing(inactive))\n\u001b[1;32m--> 482\u001b[0m labels \u001b[38;5;241m=\u001b[39m \u001b[43mclassifier_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43minverse_data\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    483\u001b[0m distances \u001b[38;5;241m=\u001b[39m distance_fn(sp\u001b[38;5;241m.\u001b[39msparse\u001b[38;5;241m.\u001b[39mcsr_matrix(data))\n\u001b[0;32m    484\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m data, labels, distances\n",
      "Cell \u001b[1;32mIn[32], line 16\u001b[0m, in \u001b[0;36mlime_predict\u001b[1;34m(texts)\u001b[0m\n\u001b[0;32m     14\u001b[0m attention_mask \u001b[38;5;241m=\u001b[39m inputs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mattention_mask\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[1;32m---> 16\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mfunctional\u001b[38;5;241m.\u001b[39msoftmax(outputs\u001b[38;5;241m.\u001b[39mlogits, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mnumpy()\n",
      "File \u001b[1;32mc:\\Users\\prans\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\prans\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32mc:\\Users\\prans\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\transformers\\models\\roberta\\modeling_roberta.py:1320\u001b[0m, in \u001b[0;36mRobertaForSequenceClassification.forward\u001b[1;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, labels, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m   1312\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1313\u001b[0m \u001b[38;5;124;03mlabels (`torch.LongTensor` of shape `(batch_size,)`, *optional*):\u001b[39;00m\n\u001b[0;32m   1314\u001b[0m \u001b[38;5;124;03m    Labels for computing the sequence classification/regression loss. Indices should be in `[0, ...,\u001b[39;00m\n\u001b[0;32m   1315\u001b[0m \u001b[38;5;124;03m    config.num_labels - 1]`. If `config.num_labels == 1` a regression loss is computed (Mean-Square loss), If\u001b[39;00m\n\u001b[0;32m   1316\u001b[0m \u001b[38;5;124;03m    `config.num_labels > 1` a classification loss is computed (Cross-Entropy).\u001b[39;00m\n\u001b[0;32m   1317\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1318\u001b[0m return_dict \u001b[38;5;241m=\u001b[39m return_dict \u001b[38;5;28;01mif\u001b[39;00m return_dict \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39muse_return_dict\n\u001b[1;32m-> 1320\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mroberta\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1321\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1322\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1323\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtoken_type_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken_type_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1324\u001b[0m \u001b[43m    \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1325\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1326\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1327\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1328\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1329\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1330\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1331\u001b[0m sequence_output \u001b[38;5;241m=\u001b[39m outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m   1332\u001b[0m logits \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclassifier(sequence_output)\n",
      "File \u001b[1;32mc:\\Users\\prans\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\prans\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32mc:\\Users\\prans\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\transformers\\models\\roberta\\modeling_roberta.py:976\u001b[0m, in \u001b[0;36mRobertaModel.forward\u001b[1;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m    969\u001b[0m \u001b[38;5;66;03m# Prepare head mask if needed\u001b[39;00m\n\u001b[0;32m    970\u001b[0m \u001b[38;5;66;03m# 1.0 in head_mask indicate we keep the head\u001b[39;00m\n\u001b[0;32m    971\u001b[0m \u001b[38;5;66;03m# attention_probs has shape bsz x n_heads x N x N\u001b[39;00m\n\u001b[0;32m    972\u001b[0m \u001b[38;5;66;03m# input head_mask has shape [num_heads] or [num_hidden_layers x num_heads]\u001b[39;00m\n\u001b[0;32m    973\u001b[0m \u001b[38;5;66;03m# and head_mask is converted to shape [num_hidden_layers x batch x num_heads x seq_length x seq_length]\u001b[39;00m\n\u001b[0;32m    974\u001b[0m head_mask \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_head_mask(head_mask, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mnum_hidden_layers)\n\u001b[1;32m--> 976\u001b[0m encoder_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoder\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    977\u001b[0m \u001b[43m    \u001b[49m\u001b[43membedding_output\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    978\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextended_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    979\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    980\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    981\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_extended_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    982\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    983\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    984\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    985\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    986\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    987\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    988\u001b[0m sequence_output \u001b[38;5;241m=\u001b[39m encoder_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m    989\u001b[0m pooled_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpooler(sequence_output) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpooler \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\prans\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\prans\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32mc:\\Users\\prans\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\transformers\\models\\roberta\\modeling_roberta.py:631\u001b[0m, in \u001b[0;36mRobertaEncoder.forward\u001b[1;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m    620\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_gradient_checkpointing_func(\n\u001b[0;32m    621\u001b[0m         layer_module\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m,\n\u001b[0;32m    622\u001b[0m         hidden_states,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    628\u001b[0m         output_attentions,\n\u001b[0;32m    629\u001b[0m     )\n\u001b[0;32m    630\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 631\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[43mlayer_module\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    632\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    633\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    634\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlayer_head_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    635\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    636\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    637\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    638\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    639\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    641\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m layer_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m    642\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m use_cache:\n",
      "File \u001b[1;32mc:\\Users\\prans\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\prans\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32mc:\\Users\\prans\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\transformers\\models\\roberta\\modeling_roberta.py:520\u001b[0m, in \u001b[0;36mRobertaLayer.forward\u001b[1;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[0;32m    508\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\n\u001b[0;32m    509\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    510\u001b[0m     hidden_states: torch\u001b[38;5;241m.\u001b[39mTensor,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    517\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[torch\u001b[38;5;241m.\u001b[39mTensor]:\n\u001b[0;32m    518\u001b[0m     \u001b[38;5;66;03m# decoder uni-directional self-attention cached key/values tuple is at positions 1,2\u001b[39;00m\n\u001b[0;32m    519\u001b[0m     self_attn_past_key_value \u001b[38;5;241m=\u001b[39m past_key_value[:\u001b[38;5;241m2\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m past_key_value \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m--> 520\u001b[0m     self_attention_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mattention\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    521\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    522\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    523\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    524\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    525\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mself_attn_past_key_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    526\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    527\u001b[0m     attention_output \u001b[38;5;241m=\u001b[39m self_attention_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m    529\u001b[0m     \u001b[38;5;66;03m# if decoder, the last output is tuple of self-attn cache\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\prans\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\prans\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32mc:\\Users\\prans\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\transformers\\models\\roberta\\modeling_roberta.py:447\u001b[0m, in \u001b[0;36mRobertaAttention.forward\u001b[1;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[0;32m    437\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\n\u001b[0;32m    438\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    439\u001b[0m     hidden_states: torch\u001b[38;5;241m.\u001b[39mTensor,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    445\u001b[0m     output_attentions: Optional[\u001b[38;5;28mbool\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    446\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[torch\u001b[38;5;241m.\u001b[39mTensor]:\n\u001b[1;32m--> 447\u001b[0m     self_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mself\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    448\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    449\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    450\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    451\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    452\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    453\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    454\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    455\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    456\u001b[0m     attention_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput(self_outputs[\u001b[38;5;241m0\u001b[39m], hidden_states)\n\u001b[0;32m    457\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m (attention_output,) \u001b[38;5;241m+\u001b[39m self_outputs[\u001b[38;5;241m1\u001b[39m:]  \u001b[38;5;66;03m# add attentions if we output them\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\prans\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\prans\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32mc:\\Users\\prans\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\transformers\\models\\roberta\\modeling_roberta.py:325\u001b[0m, in \u001b[0;36mRobertaSdpaSelfAttention.forward\u001b[1;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[0;32m    313\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mforward(\n\u001b[0;32m    314\u001b[0m         hidden_states,\n\u001b[0;32m    315\u001b[0m         attention_mask,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    320\u001b[0m         output_attentions,\n\u001b[0;32m    321\u001b[0m     )\n\u001b[0;32m    323\u001b[0m bsz, tgt_len, _ \u001b[38;5;241m=\u001b[39m hidden_states\u001b[38;5;241m.\u001b[39msize()\n\u001b[1;32m--> 325\u001b[0m query_layer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtranspose_for_scores(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mquery\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m    327\u001b[0m \u001b[38;5;66;03m# If this is instantiated as a cross-attention module, the keys and values come from an encoder; the attention\u001b[39;00m\n\u001b[0;32m    328\u001b[0m \u001b[38;5;66;03m# mask needs to be such that the encoder's padding tokens are not attended to.\u001b[39;00m\n\u001b[0;32m    329\u001b[0m is_cross_attention \u001b[38;5;241m=\u001b[39m encoder_hidden_states \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\prans\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\prans\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32mc:\\Users\\prans\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\linear.py:125\u001b[0m, in \u001b[0;36mLinear.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    124\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 125\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from lime.lime_text import LimeTextExplainer\n",
    "import numpy as np\n",
    "\n",
    "# Initialize LIME explainer\n",
    "explainer = LimeTextExplainer(class_names=[\"Non-Sexist\", \"Sexist\"])\n",
    "\n",
    "# Define function for LIME prediction\n",
    "\n",
    "\n",
    "def lime_predict(texts):\n",
    "    inputs = tokenizer(texts, truncation=True, padding=True,\n",
    "                       max_length=128, return_tensors=\"pt\")\n",
    "    input_ids = inputs[\"input_ids\"]\n",
    "    attention_mask = inputs[\"attention_mask\"]\n",
    "    with torch.no_grad():\n",
    "        outputs = model(input_ids, attention_mask=attention_mask)\n",
    "    return torch.nn.functional.softmax(outputs.logits, dim=1).numpy()\n",
    "\n",
    "\n",
    "# Explain a sexist tweet\n",
    "exp = explainer.explain_instance(sample_text_sexims, lime_predict, num_features=10)\n",
    "exp.show_in_notebook()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\prans\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RobertaForSequenceClassification(\n",
       "  (roberta): RobertaModel(\n",
       "    (embeddings): RobertaEmbeddings(\n",
       "      (word_embeddings): Embedding(50265, 1024, padding_idx=1)\n",
       "      (position_embeddings): Embedding(514, 1024, padding_idx=1)\n",
       "      (token_type_embeddings): Embedding(1, 1024)\n",
       "      (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): RobertaEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-23): 24 x RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSdpaSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (classifier): RobertaClassificationHead(\n",
       "    (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "    (out_proj): Linear(in_features=1024, out_features=2, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
    "import torch\n",
    "\n",
    "# Load model and tokenizer\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"saved_model\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"saved_model\")\n",
    "\n",
    "# Move model to GPU if available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(text):\n",
    "    return tokenizer(text, truncation=True, padding=\"max_length\", max_length=64, return_tensors=\"pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted label: 1, Probabilities: [[0.015625067055225372, 0.9843749403953552]]\n"
     ]
    }
   ],
   "source": [
    "def predict(text):\n",
    "    inputs = preprocess(text)\n",
    "    # Move to GPU if available\n",
    "    inputs = {key: value.to(device) for key, value in inputs.items()}\n",
    "\n",
    "    with torch.no_grad():  # Disable gradient computation for inference\n",
    "        outputs = model(**inputs)\n",
    "\n",
    "    logits = outputs.logits\n",
    "    probabilities = torch.nn.functional.softmax(\n",
    "        logits, dim=-1)  # Convert to probabilities\n",
    "    predicted_class = torch.argmax(\n",
    "        probabilities, dim=1).item()  # Get predicted label\n",
    "\n",
    "    return predicted_class, probabilities.tolist()\n",
    "\n",
    "\n",
    "# Example usage\n",
    "text = \"Women should not be allowed to drive.\"  # Example input\n",
    "label, probs = predict(text)\n",
    "print(f\"Predicted label: {label}, Probabilities: {probs}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
